---
layout: post
title: L4-TCP
categories: 计算机网络
related_posts: True
tags:
toc:
  sidebar: left
---

## L4-TCP

### 1. concepts

![alt text](imgs/4.1_TCP_image-1.png)

- **序号**: 用于对字节流进行编号,例如序号为 301,表示第一个字节的编号为 301,如果携带的数据长度为 100 字节,那么下一个报文段的序号应为 401.

- **确认号**: 期望收到的下一个报文段的序号.例如 B 正确收到 A 发送来的一个报文段,序号为 501,携带的数据长度为 200 字节,因此 B 期望下一个报文段的序号为 701,B 发送给 A 的确认报文段中确认号就为 701.

- **数据偏移**: 指的是数据部分距离报文段起始处的偏移量,实际上指的是首部的长度.

- **确认 ACK**: 当 ACK=1 时确认号字段有效,否则无效.TCP 规定,在连接建立后所有传送的报文段都必须把 ACK 置 1.

- **同步 SYN**: 在连接建立时用来同步序号.当 SYN=1,ACK=0 时表示这是一个连接请求报文段.若对方同意建立连接,则响应报文中 SYN=1,ACK=1.

- **终止 FIN**: 用来释放一个连接,当 FIN=1 时,表示此报文段的发送方的数据已发送完毕,并要求释放连接.

- **窗口**: 窗口值作为接收方让发送方设置其发送窗口的依据.之所以要有这个限制,是因为接收方的数据缓存空间是有限的.

简单来说

- TCP提供可靠交付.**无差错/不丢失/不重复/并且按序到达**
- TCP可以有 **拥塞控制的**.会意识到包丢弃了或者网络环境不好了,会根据情况调整自己的行为(慢启动)
- TCP是一个 **有状态服务**,清楚记录发送的包,接收的包,累计确认.

#### 1.1 三次握手

三次握手和四次挥手是TCP协议中建立连接和断开连接的过程。
![alt text](imgs/4.1_TCP_image.png)

- 然后客户端主动发起连接SYN,之后处于SYN-SENT状态.
- 服务端收到发起的连接,返回SYN,并且ACK客户端的SYN,之后处于SYN-RCVD状态.
- 客户端收到服务段发送的SYN和ACK后,发送ACK的ACK,之后处于ESTABLISHED的状态,因为它一发一收成功了.
- 服务段收到ACK的ACK,就会处于ESTABLISHED状态,因为它也一发一收成功了.

- 主动建立连接方A的TCP向主机B发出连接请求报文段,其首部中的`SYN`(同步)标志位应置为1,表示想与目标主机B进行通信,并发送一个同步序列号`x`进行同步,**表明在后面传送数据时的第一个数据字节的序号**是`x + 1`.`SYN`同步报文会指明客户端使用的端口以及TCP连接的初始序号,A进入`SYN_SENT`状态
- 接收连接方B的TCP收到连接请求报文段后,如同意则发回确认.在确认报中应将`ACK`位和`SYN`位置1,表示客户端的请求被接受.确认号应为`x + 1`,同时也为自己选择一个序号`y`,B进入`SYN_RCVD`状态
- 主动方A的TCP收到目标主机B的确认后要向目标主机B给出确认,其`ACK`置1,确认号为`y +1`,而自己的序号为`x + 1`,A进入`ESTABLISHED状态`,B收到报文后也进入`ESTABLISHED`状态

##### 1.1.1 为什么要三次握手？

第三次握手是为了防止失效的连接请求到达服务器,让服务器错误打开连接.

客户端发送的连接请求如果在网络中滞留,那么就会隔很长一段时间才能收到服务器端发回的连接确认.客户端等待一个超时重传时间之后,就会重新请求连接.但是这个滞留的连接请求最后还是会到达服务器,如果不进行三次握手,那么服务器就会打开两个连接.如果有第三次握手,客户端会忽略服务器之后发送的对滞留连接请求的连接确认,不进行第三次握手,因此就不会再次打开连接.

- 三次握手的目的是**建立可靠的通信信道**,说到通讯,简单来说就是数据的发送与接收,而**三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的**
- **经典场景**:客户端发送了第一个请求连接并且没有丢失,只是因为在**网络结点中滞留的时间太长**了
  - 由于TCP的客户端迟迟没有收到确认报文,以为服务器没有收到,此时**重新向服务器发送这条报文**,此后客户端和服务器经过两次握手完成连接,传输数据,然后关闭连接
  - 此时此前滞留的那一次请求连接,网络通畅了到达服务器,**这个报文本该是失效的**,但是,**两次握手的机制将会让客户端和服务器再次建立连接,这将导致不必要的错误和资源的浪费**
  - **如果采用的是三次握手,就算是那一次失效的报文传送过来了,服务端接受到了那条失效报文并且回复了确认报文,但是客户端不会再次发出确认.由于服务器收不到确认,就知道客户端并没有请求连接**
- **避免资源浪费**
  - 如果客户端的 `SYN` 阻塞了,**重复发送多次** `SYN` 报文,那么服务器在**收到请求后就会建立多个冗余的无效链接,造成不必要的资源浪费**

##### 1.1.2 syn和ack是什么？

- **SYN**：
  这是一个缩写，全称是Synchronize Sequence Numbers。
  在TCP/IP协议中，SYN标志位的设置表示一个新的连接请求，用于同步序列号。

  1. 当TCP连接的一方想要建立连接时，它将发送一个SYN标志位为1的数据包给另一方，同时提供一个初始序列号。
  2. 这个序列号在TCP连接期间是唯一的，并且每传送一个字节，序列号就会增加。

- **ACK**：
  这是一个缩写，全称是Acknowledgement。
  在TCP/IP协议中，ACK标志位的设置表示确认。
  1. 当TCP连接的一方收到数据后，它将发送一个ACK标志位为1的数据包给另一方，表示已经收到了数据。
  2. ACK数据包中还包含一个确认号，这个确认号等于收到的数据的最后一个字节的序列号加1，表示期望接收的下一个字节的序列号。

在TCP的三次握手过程中，SYN和ACK标志位都起到了关键的作用。

##### 1.1.3 TCP三次握手中,最后一次回复丢失,会发生什么?

- 如果最后一次ACK在网络中丢失,那么**Server端(服务端)该TCP连接的状态仍为SYN_RECV**,并且**根据 TCP的超时重传机制依次等待3秒/6秒/12秒后重新发送 SYN+ACK 包**,以便 **Client(客户端)重新发送ACK包**
- **如果重发指定次数后,仍然未收到ACK应答**,那么一段时间后,**Server(服务端)自动关闭这个连接** .**当失败时服务器并不会重传ACK报文,而是直接发送RTS报文段,进入CLOSED状态.这样做的目的是为了`防止SYN洪泛攻击`**
- **但是Client(客户端)认为这个连接已经建立**,如果Client(客户端])端向Server(服务端)发送数据,**Server端(服务端)将以RST包(Reset,标示复位,用于异常的关闭连接)响应**,此时,**客户端知道第三次握手失败**

##### 1.1.4 TCP的三次握手是否都可以携带数据

- 第一次和第二次是不可以携带数据的,但是第三次是可以携带数据的
- 假如第一次握手可以携带数据的话,那对于服务器是不是太危险了,有人如果恶意攻击服务器,每次都在第一次握手中的SYN报文中放入大量数据.而且频繁重复发SYN报文,**服务器会花费很多的时间和内存空间去接收这些报文**
- 第三次握手,**此时客户端已经处于ESTABLISHED状态**.**对于客户端来说,他已经建立起连接了,并且已经知道服务器的接收和发送能力是正常的.所以也就可以携带数据了**

##### 1.1.5 TCP三次握手时的第一次的seq序号是怎样产生的

第一次的序号是随机序号,但也不是完全随机,它是使用一个ISN算法得到的.

seq = C + H (源IP地址,目的IP地址,源端口,目的端口).其中,C是一个计时器,每隔一段时间值就会变大,H是消息摘要算法,输入是一个四元组(源IP地址,目的IP地址,源端口,目的端口).

#### 1.2 四次挥手

- 四次挥手断开连接:

  - 第一次挥手:当client没有数据要发送给server了,他会给server发送一个FIN报文,告诉server:"我已经没有数据要发给你了,但是你要是还想给我发数据的话,你就接着发,但是你得告诉我你收到我的关闭信息了",这是第一次挥手,挥手之后client进入FIN_WAIT_1的第一阶段
  - 第二次挥手:当server收到client发来的FIN报文后,告诉client:"我收到你的FIN消息了,但是你等我发完的"此时给client返回一个ACK信息,并且呢ack=seq+1,这是第二次挥手,挥手之后呢server进入CLOSE_WAIT阶段,而client收到之后处于FIN_WAIT_2第二阶段
  - 第三次挥手:当server发完所有数据时,他会给client发送一个FIN报文,告诉client说"我传完数据了,现在要关闭连接了",然后呢server变成LAST_ACK状态,等着client最后的ACK信息,这是第三次挥手
  - 第四次挥手:当client收到这个FIN报文时,他会对这个消息进行确认,即给server发ACK信息,但是它不相信网络,怕server收不到信息,它会进入TIME_WAIT状态,万一server没收到ACK消息它可以可以重传,而当server收到这个ACK信息后,就正式关闭了tcp连接,处于CLOSED状态,而client等待了2MSL这样长时间后还没等到消息,它知道server已经关闭连接了,于是乎他自己也断开了,这是第四次挥手,这样tcp连接就断开了

- 主动关闭主机A的应用进程先向其TCP发出连接释放请求,并且不再发送数据.TCP通知对方要释放从A到B这个方向的连接,将发往主机B的TCP报文段首部的终止比特`FIN`置1,**其序号x等于前面已传送过的数据的最后一个字节的序号加1**
- 被动关闭主机B的TCP收到释放连接通知后即发出确认,其序号为`y`,**确认号为`x + 1`**,同时通知高层应用进程,这样,从A到B的连接就释放了,**连接处于半关闭状态**.但**若主机B还有一些数据要发送主机A,则可以继续发送**.主机A只要正确收到数据,仍应向主机B发送确认
- **若主机B不再向主机A发送数据,其应用进程就通知TCP释放连接**.主机B发出的连接释放报文段必须**将终止位`FIN`和确认位`ACK`置1**,**并使其序号仍为`y`,但还必须重复上次已发送过的`ACK` = `x + 1`**
- **主机A必须对此发出确认,将`ACK`置1,`ACK `= `y + 1`,而自己的序号是`x + 1`**.这样才把从B到A的反方向的连接释放掉.主机A的TCP再向其应用进程报告,整个连接已经全部释放

##### 1.2.1 time_wait有什么用？

`TIME_WAIT`是TCP连接中的一个状态，它在四次挥手断开连接的过程中出现。当TCP连接的一方（通常是客户端）发送完最后一个ACK确认包后，它会进入`TIME_WAIT`状态。

`TIME_WAIT`的主要作用有两个：

1. **确保最后一个ACK确认包能被对方收到**：网络传输是不可靠的，最后一个ACK包可能会在网络中丢失，导致对方（通常是服务器）收不到。如果客户端在发送完ACK包后立即关闭连接，那么服务器就无法知道ACK包是否已经被客户端收到，可能会重复发送FIN包。`TIME_WAIT`状态就是为了解决这个问题，客户端会在`TIME_WAIT`状态等待一段时间（通常是2倍的MSL，Maximum Segment Lifetime，报文最大生存时间），如果在这段时间内没有收到服务器的FIN包，就认为ACK包已经被服务器收到，然后关闭连接。

2. **防止“旧”连接的数据包在新连接中出现**：由于网络的延迟，已经关闭的连接的数据包可能会在网络中滞留一段时间，然后才到达接收方。如果立即关闭连接并立即打开新的连接，这些滞留的数据包可能会在新的连接中出现，导致错误。`TIME_WAIT`状态就是为了解决这个问题，客户端会在`TIME_WAIT`状态等待一段时间，确保网络中的所有“旧”数据包都已经被接收，然后再打开新的连接。

因此，`TIME_WAIT`是TCP协议保证数据可靠传输的重要机制之一。

#### 1.3 序号机制(可靠机制)

TCP的序号机制是TCP协议保证数据可靠传输的关键机制之一。

在TCP协议中，每一个发送的数据包都会被赋予一个唯一的序号。这个序号在TCP连接期间是连续的，每发送一个字节，序号就会增加。

当接收方收到数据包后，它会根据这些数据包的序号对它们进行排序，确保数据是按照发送的顺序接收的。然后，接收方会发送一个ACK（确认）包给发送方，ACK包中包含一个确认号，这个确认号等于收到的数据的最后一个字节的序列号加1，表示期望接收的下一个字节的序列号。

如果发送方没有收到接收方的ACK包，或者收到的确认号不正确，就会认为数据包丢失，然后重新发送数据包。这就是TCP的重传机制。

此外，TCP的序号机制还可以处理数据包的乱序问题。如果接收方收到的数据包不是按照序号顺序到达的，它可以使用缓冲区暂存这些数据包，然后再按照序号顺序重新组织它们。

因此，TCP的序号机制确保了数据的完整性和正确性，是实现可靠传输的关键。

#### 1.4 校验机制(可靠机制)

TCP使用校验和（Checksum）机制来校验数据的完整性和正确性。

在TCP协议中，每个数据包都包含一个校验和字段。这个校验和是在发送数据包之前计算的，计算方法是对整个数据包（包括TCP头部和数据部分）进行二进制求和，然后取反。

当接收方收到数据包后，它会使用同样的方法计算数据包的校验和，然后与数据包中的校验和字段进行比较。如果两者相同，说明数据包没有在传输过程中被修改，数据的完整性和正确性得到了保证。如果两者不同，说明数据包在传输过程中可能被修改，接收方就会丢弃这个数据包，并发送一个请求重传的信号给发送方。

这就是TCP的校验机制。虽然它不能保证100%的正确性（因为可能存在两个不同的数据包有相同的校验和），但在大多数情况下，它都能有效地检测出数据的错误。

#### 1.5 窗口滑动(流量控制)

TCP的窗口滑动（Sliding Window）是一种流量控制机制，用于防止发送方发送过多数据，从而导致接收方处理不过来。

在滑动窗口机制中，接收方会告诉发送方它的接收窗口的大小，这个大小是基于接收方当前缓冲区的空闲空间来确定的。发送方在发送数据时，不能发送超过接收窗口大小的数据。

当接收方处理完一部分数据并释放了缓冲区空间后，它会更新窗口大小并通知发送方。发送方会根据新的窗口大小来调整发送数据的速率。

这样，接收方就可以根据自己的处理能力来控制发送方的发送速率，从而实现流量控制。

##### 1.5.1 流量控制

##### 1.5.2 拥塞控制

TCP的滑动窗口大小的变化主要取决于两个因素:流量控制和拥塞控制.

滑动窗口的大小主要由两个因素决定：流量控制和拥塞控制。

1. 流量控制：接收方通过ACK报文告诉发送方自己的接收窗口大小，这个大小是基于接收方当前缓冲区的空闲空间来确定的。发送方在发送数据时，不能发送超过接收窗口大小的数据。当接收方处理完一部分数据并释放了缓冲区空间后，它会更新窗口大小并通知发送方。发送方会根据新的窗口大小来调整发送数据的速率。

2. 拥塞控制：当网络出现拥塞时，发送方会减小其发送窗口的大小，以减少发送到网络中的数据量，从而缓解网络拥塞。当网络拥塞消失后，发送方会逐渐增大其发送窗口的大小，以提高数据传输的效率。

滑动窗口的大小会根据网络的状态和接收方的处理能力动态调整，以实现高效且可靠的数据传输。

---

窗口是缓存的一部分,用来暂时存放字节流.发送方和接收方各有一个窗口,接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小,发送方根据这个值和其它信息设置自己的窗口大小.

发送窗口内的字节都允许被发送,接收窗口内的字节都允许被接收.如果发送窗口左部的字节已经发送并且收到了确认,那么就将发送窗口向右滑动一定距离,直到左部第一个字节不是已发送并且已确认的状态;接收窗口的滑动类似,接收窗口左部字节已经发送确认并交付主机,就向右滑动接收窗口.

接收窗口只会对窗口内最后一个按序到达的字节进行确认,例如接收窗口已经收到的字节为 {31, 34, 35},其中 {31} 按序到达,而 {34, 35} 就不是,因此只对字节 31 进行确认.发送方得到一个字节的确认之后,就知道这个字节之前的所有字节都已经被接收.

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" width="800"/> </div><br>

详见 [TCP-IP详解:滑动窗口SlidingWindow](https://blog.csdn.net/wdscq1234/article/details/52444277)和[TCP滑动窗口](https://www.cnblogs.com/alifpga/p/7675850.html)

TCP的滑动窗口用来控制接收方和发送方的发送速率,避免拥塞的发生.滑动窗口其实就是接收端的缓冲区大小,用来告诉发送方对它发送的数据有多大的缓冲空间.在接收方的滑动窗口已知的情况下,当接收方确认了连续的数据序列之后,发送方的滑动窗口向后滑动,发送下一个数据序列.

接收方会在每个ACK数据包中附带自己当前的接受窗口(滑动窗口)的大小,方便发送方进行控制.

- SACK
  还有一种 **SACK**,就是可以在TCP头加一个SACK,例如可以发送ACK6,ACK8,ACK9,那发送方就知道7丢了.<br>
  有了窗口大小,重传机制,那么我们可以继续看一下流量的控制了.<br>
  在对于包的确认中,同时会携带一个窗口的大小.<br>
  接到4的ACK,右移<br>

#### 1.6 拥塞控制

- **拥塞控制**:使用拥塞窗口机制,控制发送窗口大小,减少网络拥塞,避免因网络拥塞导致频繁丢包

* tcp拥塞4个控制算法
  防止过多的数据注入到网络中,这样可以使网络中的路由器或链路不致过载,拥塞控制自然也是控制发送者的流量,拥塞控制有四种算法,**慢启动/拥塞避免,快速重传和快速恢复**

发送方维持一个拥塞窗口 cwnd \( congestion window \)的状态变量.拥塞窗口的大小取决于网络的拥塞程度,并且动态地在变化.发送方让自己的发送窗口等于拥塞窗口和接受窗口的较小值.

(1)**慢启动**.慢启动算法的思路是当主机开始发送数据时,先以比较小的拥塞窗口进行发送,然后每次翻倍,也就是说,由小到大逐渐增加拥塞窗口的大小,而这个大小是指数增长的,即1/2/4/8/16 \*为了防止拥塞窗口cwnd增长过大引起网络拥塞,还要另外设置一个慢启动阈值ssthresh状态变量,当拥塞窗口的大小超过慢启动阈值的时候( cwnd > ssthresh 时),停止使用慢开始算法而改用拥塞避免算法

(2)**拥塞避免**.拥塞避免算法的思路是让拥塞窗口cwnd缓慢地增大,即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1,而不是加倍.

(3)**快速重传**.当发送端连续收到三个重复的ack时,表示该数据段已经丢失,需要重发.此时慢启动阈值ssth变为原来一半,拥塞窗口cwnd变为ssth+3,然后+1+1的发(每一轮rtt+1)

(4)**快速恢复**.当超过设定的时间没有收到某个报文段的ack时,表示网络拥塞,慢启动阈值ssth变为原来一半,拥塞窗口cwnd=1,进入慢启动阶段

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/51e2ed95-65b8-4ae9-8af3-65602d452a25.jpg" width="500"/> </div><br>

TCP 主要通过四个算法来进行拥塞控制:慢开始/拥塞避免/快重传/快恢复.

发送方需要维护一个叫做拥塞窗口(cwnd)的状态变量,注意拥塞窗口与发送方窗口的区别:拥塞窗口只是一个状态变量,实际决定发送方能发送多少数据的是发送方窗口.

为了便于讨论,做如下假设:

- 接收方有足够大的接收缓存,因此不会发生流量控制;
- 虽然 TCP 的窗口基于字节,但是这里设窗口的大小单位为报文段.

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/910f613f-514f-4534-87dd-9b4699d59d31.png" width="800"/> </div><br>

cwnd就是怕把网络塞满了.<br>
拥塞窗口和滑动窗口共同控制发送的速度🛹<br>
`LastByteSent-LastByteAcked<=min{cwnd,rwnd}`两者取最小的值,作为发送的速度.<br>
通道的容量=带宽\*往返延迟,像这样<br>
![网络通道](./img/controldata.jpg)<br>
拥塞控制主要用来避免两个现象,**包丢失和超时重传**<br>
一旦出现包丢失或超时,就是速度太快了,放慢脚步.就像通过漏斗往瓶子里灌水,不能一桶水一下子倒进去,肯定会溅出来,一开始慢慢倒,就是一开始慢慢发的意思,如果发现总能倒进去,就会越倒越快.这就是慢启动.如图<br>
![控制](./img/mapDataControl.jpg)<br>
一条TCP连接开始,cwnd就设置发一个报文段,一次只能发送一个,收到确认就发两个,cwnd加1,两个确认就发四个,四个确认就发8个,如此指数增长.<br>
sshresh是65535个字节,如果超过这个值就会降下来,每次降多少呢?降1/cwnd,每次增加1/cwnd,成线性了.但是要是出现了拥塞,就会一下子回到解放前,shhresh就会设为swnd/2,就是一半,然后由每次增加1.这时候看到网络就一卡一卡的<br>
但是现在就是快速重传占主导,直接发三个ACK,前一个包的ACK,然后不必等超时,直接重传,这样,swnd就会减半,然后sshresh=cwnd,也就是减半,这时候cwnd = sshresh+3,没有回到解放前,而是➕了3.<br>
快速重传就是橙色那条线<br>
好了,重传说完了,这时候,我们再来看一下粘包的问题.

发送的最初执行慢开始,令 cwnd = 1,发送方只能发送 1 个报文段;当收到确认后,将 cwnd 加倍,因此之后发送方能够发送的报文段数量为:2/4/8 ...

注意到慢开始每个轮次都将 cwnd 加倍,这样会让 cwnd 增长速度非常快,从而使得发送方发送的速度增长速度过快,网络拥塞的可能性也就更高.设置一个慢开始门限 ssthresh,当 cwnd >= ssthresh 时,进入拥塞避免,每个轮次只将 cwnd 加 1.

如果出现了超时,则令 ssthresh = cwnd / 2,然后重新执行慢开始.

- **拥塞控制**:**网络拥塞现象是指到达通信子网中某一部分的分组数量过多,使得该部分网络来不及处理,以致引起这部分乃至整个网络性能下降的现象**.严重时甚至会导致网络通信业务陷入停顿,即出现死锁现象.拥塞控制是处理网络拥塞现象的一种机制

  - 方法:有一个叫**慢启动门限** `ssthresh` (slow start threshold)状态变量,一般来说 `ssthresh` 的大小是 `65535` 字节

    - 慢开始( slow-start ):当 `cwnd` < `ssthresh` 时,使用慢启动算法,每当收到一个 ACK 时,指数级增长`cwnd`,如1,2,4,8...
    - 拥塞避免( congestion avoidance ):当 `cwnd` >= `ssthresh` 时,就会使用拥塞避免算法,线性增长`cwnd`,每当收到一个 ACK 时,`cwnd` 增加 `1/cwnd`.一直增长着,网络就会慢慢进入了拥塞的状况了,于是就会**出现丢包现象**,这时就需要对丢失的数据包进行重传.**当触发了重传机制,也就进入了'拥塞发生算法'**
    - 超时重传:`ssthresh` 设为 `cwnd/2` ,`cwnd` 重置为 1,**重新开始慢开始算法**
    - 快重传( fast retransmit ):当接收方发现丢了一个中间包的时候,**发送三次前一个包的 ACK**,于是**发送端就会快速地重传**,不必等待超时再重传.**TCP 认为这种情况不严重,因为大部分没丢**,只丢了一小部分,则 `ssthresh` 和 `cwnd` 变化如下:`cwnd` = `cwnd/2` ,也就是设置为原来的一半;`ssthresh` = `cwnd `;**进入快恢复算法**
    - 快恢复( fast recovery ):拥塞窗口 `cwnd` = `ssthresh` + 3( 3 的意思是确认有 3 个数据包被收到了)
      - 重传丢失的数据包
      - 如果再收到重复的 ACK,那么` cwnd` 增加 1
      - 如果收到新数据的 ACK 后,把 `cwnd `设置为第一步中的 `ssthresh `的值,原因是该 ACK 确认了新的数据,说明从 duplicated ACK 时的数据都已收到,该恢复过程已经结束,可以回到恢复之前的状态了,也即**再次进入拥塞避免状态**

    <img src="imgs/network/block_ctrl.png" alt="block_ctrl" style="zoom: 50%;" />

    <img src="imgs/network/fast_restransmit.png" alt="fast_restransmit" style="zoom:50%;" />

    <img src="imgs/network/flow_diag.png" alt="flow_diag" style="zoom:50%;" />

#### 1.7 流量控制

- 流量控制:TCP采用大小可变的滑动窗口进行流量控制.**窗口大小的单位是字节**,在TCP报文段首部的窗口字段写入的数值就是当前给对方设置的发送窗口数值的上限,发送窗口在连接建立时由双方商定.但在通信的过程中,**接收端可根据自己的资源情况,随时动态地调整对方的发送窗口上限值**

拥塞控制是防止过多的数据注入到网络中,导致网络发生拥塞;而流量控制是防止发送方一下子发送过多的数据到接收方,导致接收方缓存放不下.两种算法都是对发送方的行为进行控制的.

所谓流量控制就是让发送方发送速率不要过快,让接收方来得及接收.利用TCP报文段中的窗口大小字段来控制发送方的发送窗口不大于接收方发回的窗口大小就可以实施流量控制.

考虑一种特殊的情况,就是接收方若没有缓存足够使用,就会发送零窗口大小的报文,此时发送放将发送窗口设置为0,停止发送数据.之后接收方有足够的缓存,发送了非零窗口大小的报文,但是这个报文在中途丢失的,那么发送方的发送窗口就一直为零导致死锁.

解决这个问题,TCP为每一个连接设置一个持续计时器(persistence timer).只要TCP的一方收到对方的零窗口通知,就启动该计时器,周期性的发送一个零窗口探测报文段.对方就在确认这个报文的时候给出现在的窗口大小(注意:TCP规定,即使设置为零窗口,也必须接收以下几种报文段:零窗口探测报文段/确认报文段和携带紧急数据的报文段).

TCP连接的每一方都有固定大小的缓冲空间,TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据.当接收方来不及处理发送方的数据,能提示发送方降低发送的速率,防止包丢失.TCP使用的流量控制协议是可变大小的滑动窗口协议.
接收方有即时窗口(滑动窗口),随ACK报文发送

流量控制是为了控制发送方发送速率,保证接收方来得及接收.

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小,从而影响发送方的发送速率.将窗口字段设置为 0,则发送方不能发送数据.

如果网络出现拥塞,分组将会丢失,此时发送方会继续重传,从而导致网络拥塞程度更高.因此当出现拥塞时,应当控制发送方的速率.这一点和流量控制很像,但是出发点不同.流量控制是为了让接收方能来得及接收,而拥塞控制是为了降低整个网络的拥塞程度.

#### 1.8 超时重传

- **超时重传**(定时器):保证因链路故障未能到达数据能够被多次重发
  [ARQ协议](https://snailclimb.gitee.io/javaguide/#/./docs/cs-basics/network/other-network-questions?id=arq-%e5%8d%8f%e8%ae%ae)

* 超时重传
  当TCP发出一个段后,它启动一个定时器,等待目的端确认收到这个报文段.如果不能及时收到一个确认,将重发这个报文段.

4G时代,无线网时代,原本以为丢包是拥塞造成的,但是现在却是信号太弱造成的,所以快速重传机制用得非常频繁,包收不到就重传.这点与详解中的拥塞控制不一样,拥塞会将速度降下来,降到最低

TCP 使用超时重传来实现可靠传输:如果一个已经发送的报文段在超时时间内没有收到确认,那么就重传这个报文段.

一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT,加权平均往返时间 RTTs 计算如下:

<div align="center"><img src="https://latex.codecogs.com/gif.latex?RTTs=(1-a)*(RTTs)+a*RTT" class="mathjax-pic"/></div> <br>
其中,0 ≤ a ＜ 1,RTTs 随着 a 的增加更容易受到 RTT 的影响.

超时时间 RTO 应该略大于 RTTs,TCP 使用的超时时间计算如下:

<div align="center"><img src="https://latex.codecogs.com/gif.latex?RTO=RTTs+4*RTT_d" class="mathjax-pic"/></div> <br>
其中 RTT<sub>d</sub> 为偏差的加权平均值.

在接收方,要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认.例如已经接收到 M<sub>1</sub> 和 M<sub>2</sub>,此时收到 M<sub>4</sub>,应当发送对 M<sub>2</sub> 的确认.

在发送方,如果收到三个重复确认,那么可以知道下一个报文段丢失,此时执行快重传,立即重传下一个报文段.例如收到三个 M<sub>2</sub>,则 M<sub>3</sub> 丢失,立即重传 M<sub>3</sub>.

在这种情况下,只是丢失个别报文段,而不是网络拥塞.因此执行快恢复,令 ssthresh = cwnd / 2 ,cwnd = ssthresh,注意到此时直接进入拥塞避免.

慢开始和快恢复的快慢指的是 cwnd 的设定值,而不是 cwnd 的增长速率.慢开始 cwnd 设定为 1,而快恢复 cwnd 设定为 ssthresh.

- 快速重传
  还有一种 **快速重传机制**,也是现在这个时代用得最多的.就是发送三个冗余的ACK,例如丢了7,就发三个6,666.<br>

- 超时重试
  出现丢包,两种方法,超时重试,但是超时⌚️不能过短,一般都要大于往返时间RTT,否则会引起不必要的重传.但是不能过长,过长,访问就慢了.<br>
  那怎么办?估计往返时间,需要TCP通过采样RTT时间,进行加权平均,算出一个值,而这个值是不段变化的,因为网络状态是不断地变化的.除了采样RTT,也要采样RTT的波动范围,计算一个估计的超时时间.由于重传时间不断变化,我们也称为自适应重传算法.<br>
  要是超时超过两次,TCP的策略就是超时间隔加倍.每当遇到一次超时重传,下一次就会将超时时间将额设为先前值的两倍.<br>

* 滑动窗口机制,确立收发的边界,能让发送方知道**已经发送了多少/尚未确认的字节数/尚待发送的字节数**;**让接收方知道已经确认收到的字节数**
* 选择性重传,用于对传输出错的序列进行重传
* 重复确认和快速重传

#### 1.9 粘包/封包/拆包

- 什么是粘包现象?

  - 粘包是TCP特有现象,UDP是不存在粘包一说.TCP是面向字节流传输的,发送方引起的粘包是由TCP协议本身造成的,TCP为提高传输效率,发送方往往要收集到足够多的数据后才发送一个TCP段.若连续几次需要send的数据都很少,通常TCP会根据块的合并优化算法(Nagle)把这些数据合成一个TCP段后一次发送出去,这样接收方就收到了粘包数据.对于ssh等需要实时通信的应用,可以设置SO_NODELAY,使小包也能马上发出
  - UDP是无连接的,面向消息的,提供高效率服务.不会使用块的合并优化算法, 由于UDP支持的是一对多的模式,所以接收端的**skbuff**(套接字缓冲区)采用了链式结构来记录每一个到达的UDP包,在每个UDP包中就有了消息头(消息来源地址,端口等信息),这样,对于接收端来说,就容易进行区分处理了. **即面向消息的通信是有消息保护边界的**

- 粘包发生场景
  - 第一种:发送端需要**等缓冲区满才发送出去**,造成粘包(发送数据时间间隔很短,**数据了很小,会合到一起,产生粘包**)
  - 第二种:接收方**不及时接收缓冲区的包**,造成多个包接收(客户端发送了一段数据,服务端只收了一小部分,服务端下次再收的时候还是从缓冲区拿上次遗留的数据,产生粘包)
- 粘包解决方法

  - 粘包问题的根源在于,**接收端不知道发送端将要传送的字节流的长度**,所以解决粘包的方法就是围绕,**如何让发送端在发送数据前,把自己将要发送的字节流总大小让接收端知晓,然后接收端来一个死循环接收完所有数据**
  - 设计一个报头模块(可以是struct结构体),该模块的作用就是记录要发送的真实数据的详细信息(如数据长度等)
  - 发送时,先发报头长度,再编码报头内容然后发送,最后发真实数据内容
  - 接收时,先收报头长度,根据取出的长度收取报头内容,然后解码,从解码的结果中取出待取数据的详细信息,然后去取真实的数据内容
  - https://www.zhihu.com/question/20210025/answer/1982654161

  * 导致粘包原因的三个方面
    - 发送端等待缓冲区满之后才发送
    - TCP在发送小的数据包的时候,会合并

* 避免粘包
  - 不是要等缓冲满吗?不等就行了,每个数据设置达到相应的缓冲,立即push发送,但是恐怕会网络速度降低
  - 接收方不及时接收吗?我优化你的接收机制就好了,来多少,及时接收,但是不能完全避免,网络突然特别好,发的也超快,那也是接收方收不到
  - 接收方控制接收一定结构的字段,到了固定的结构就停止,然后合并,但是效率低了,处理多了<br>
    还有一种处理方式,就是开一个线程,只处理数据包,粘连就分开.<br>
    所以这就是粘包的情况,和分包以及处理的情况.好了,今天就到这里,后面继续补充编程实现,线程实现.

说到什么是粘包,这里有一个很特别的比喻,TCP协议本上将一块数据看成一连串的字节流,就是没有界限的一串数据,就像河流的流水一样,连绵不断,没有分界,要是没有看清数据里面是什么,根本不知道这数据还参杂着其他数据.这就形成了粘在一起的数据流,这就是粘包<br>
❓那么造成这种粘包的情况到底原因是什么呢?<br>
这里我解释一下粘包,粘包其实表述是不准确的,其实TCP是基于字节流传输的,所以根本不存在包的概念,字节流贯穿整个TCP协议,所有的错误重传/窗口大小/以及拥塞控制...等等,都是以字节为单位传输的.🚢<br>
上面我们只讲了他们的传输方式,但是基于数据的完整性我们也就称为包了.<br>
那么造成的原因是什么呢?要分析这个原因,我们先了解一下,TCP在传输的过程中建立的连接.连接分为两种,一种是长连接一种是短连接<br>
**长链接🔗** :Client和Server建立连接,不断开,一直进行报文的发送和接收<br>
**短连接🔗** :Client和Server进行一次报文的发送就建立连接,发送完就关闭.断开.这种方式常用于一对多通信,比如多个client💻对一个server💻<br>
那么在这两种连接中,那种会更容易发生粘包的问题呢?没错,就是长链接.<br>

- TCP/IP的粘包与避免介绍一下
  因为TCP为了减少额外开销,采取的是流式传输,所以接收端在一次接收的时候有可能一次接收多个包.而TCP粘包就是发送方的若干个数据包到达接收方的时候粘成了一个包.多个包首尾相接,无法区分.

导致TCP粘包的原因有三方面:

- 发送端等待缓冲区满才进行发送,造成粘包
- 接收方来不及接收缓冲区内的数据,造成粘包
- 由于TCP协议在发送较小的数据包的时候,会将几个包合成一个包后发送

避免粘包的措施:

- 通过编程,强制使TCP发生数据传送,不必等到缓冲区满
- 优化接收方接收数据的过程,使其来得及接收数据包,包括提高接收进程优先级等
- 设置固定长度的报文或者设置报文头部指示报文的长度.

* 说一下TCP的封包和拆包
  因为TCP是无边界的流传输,所以需要对TCP进行封包和拆包,确保发送和接收的数据不粘连.

- 封包:封包就是在发送数据报的时候为每个TCP数据包加上一个包头,将数据报分为包头和包体两个部分.包头是一个固定长度的结构体,里面包含该数据包的总长度.
- 拆包:接收方在接收到报文后提取包头中的长度信息进行截取.

* 那为什么长连接🔗会容易发生粘包现象呢?<br>
  在TCP连接,发送报文的时候,我们知道,到了ip层就会套上IP头,到了MAC层又会套上mac头,这样真正的数据都要套上大概20(TCP头)+20(IP头)+8(MAC头)字节,如果数据只有一个字节,那么伴随他发送的有48个字节,这样,去到接收端又要解封装,最后只取到了一个字节的数据,这不就是成本大于利润嘛!😱那么在这个问题上,如果是一个商人,为了减少成本的情况下,肯定只能让数据多一点,至少不至于那么少就发送数据,不仅是成本问题,如果不停滴发送只有一个字节或者几个字节的数据包,很可能因为不停滴发送数据包,造成网络拥塞.这时候, **Nagle算法应运而生**,将多次间隔较小,数据量小的数据,合并成一个大的数据块,然后进行封包.然后发送,这就解决了成本大于利润的问题.但是也是因为这样,产生了现在的粘包和拆包问题❕<br>
  看了太多字,给你看个图片就明白了.<br>

- 情况A,很和谐,接收端正常接收两个包,每个包都完成充满了整个缓冲区,这样没有发生拆包和粘包的情况.<br>
  ![情况A,完整的包](./img/sticky_package1.png)<br>
- 情况B,不和谐,每一段数据都很小,不充满发送端缓冲区,缓冲区等待充满才发送,这时候就会导致,发送端一次性将多段数据同时包装发送或者接收方不及时接收缓冲区的包,造成多个包接收就会导致粘包,我们看到图后头的包紧接着前一个包的数据的尾部<br>
  ![情况B,粘包](./img/sticky_package2.png)<br>
- 情况C,发送端等待缓冲区满就已发送,但是有些数据不完整,这时候会导致某些数据段被查分,就相当于一个包被拆分.<br>
  ![情况C,拆包](./img/sticky_package3.png)<br>
  其实我们应该看到,这个区别于UDP,UDP将数据当作是一条独立的消息在网络中发送,接受端只接收独立的信息,一次一个包,一次接收一次,所以这就是我们所说的UDP具有消息的保护边界.但是TCP确实不一样,他不把一个信息当成独立的包,而是把信息当成一串数据流🌊,当然在流传输后,分析流就成为了一个主要的工作.<br>
  当然,TCP将信息当成流的传输,其实是为了可靠的传输,减少额外的开销,减少包的发送.<br>
  那怎么让TCP也有消息边界保护呢?<br>

* 很简单,只需要抄UDP的处理方式就可以了.

- 固定信息的长度.UDP数据包就是一个📦一个📦的,TCP固定也相当于一个一个的了
- 把消息尺寸和消息块一起发 和UDP数据包一样,一个一个发
- 使用特殊标记区分消息间隔 这个就更简单了,知道发什么数据,使用特殊标记标记一下就好了.
  那怎么样分析流呢?怎样分析粘包呢?<br>
  当然,不是所有的包📦都需要处理,若传输的数据就是不带结构的连续流数据(如,文件),则不必把粘连的包分开.但是要是有结构的,就需要分包处理了.若是处理定长结构数据的粘包情况,就比较简单了,固定长度读取就行了,但是要是不定长就需要很复杂的处理.<br>
  而现实工程中,应该避免粘包的现象.根据发生的情况避免就行了<br>

### 2. details

#### 2.1 心跳包机制

- 心跳包之所以叫心跳包是因为:它**像心跳一样每隔固定时间发一次,以此来告诉服务器,这个客户端还活着**.事实上这是为了保持长连接,至于这个包的内容,是没有什么特别规定的,不过一般都是很小的包,或者只包含包头的一个空包.也有的心跳包中会携带一些需要定期更新的信息
- 在TCP的机制里面,**本身是存在有心跳包的机制的**,也就是TCP的选项:SO_KEEPALIVE.**系统默认是设置的2小时的心跳频率**.但是它**检查不到机器断电/网线拔出/防火墙这些断线**.而且逻辑层处理断线可能也不是那么好处理,而且这个**时间间隔默认太长**.另外,**SO_KEEPALIVE一旦设置会对系统所有的socket产生影响,可能会浪费大量流量**
- **心跳包一般来说都是在逻辑层发送空的echo包来实现的**._下一个定时器,在一定时间间隔下发送一个空包给客户端,然后客户端反馈一个同样的空包回来,服务器如果在一定时间内收不到客户端发送过来的反馈包,那就只有认定说掉线了_
- 其实,要判定掉线,**只需要send或者recv一下,如果结果为零,则为掉线**.但是,**在长连接下,有可能很长一段时间都没有数据往来**.理论上说,这个连接是一直保持连接的,但是实际情况中,如果中间节点出现什么故障是难以知道的.**更要命的是,有的节点(防火墙)会自动把一定时间之内没有数据交互的连接给断掉**.在这个时候,就需要我们的心跳包了,**用于维持长连接,保活**
- 心跳包实现思路
  - 客户端连接上服务端以后,服务端维护一个**在线用户字典**,**客户端每隔一段时间,向服务器发送一个心跳包,服务器接收到包以后,字典数据的值都会更新为0**;**一旦服务端超过规定时间没有接收到客户端发来的包,字典数据将会递增加一,当字典数据的值累计大于等于三,则视为掉线**

#### 2.2 TIME-WAIT

- 为什么还有个TIME-WAIT的时间等待?

  - **保证客户端发送的最后一个ACK报文能够到达服务器**,因为这个ACK报文可能丢失,服务器已经发送了FIN+ACK报文,请求断开,客户端却没有回应,于是服务器又会重新发送一次,而客户端就能在这个2MSL时间段内收到这个重传的报文,接着给出回应报文,并且会重启2MSL计时器
  - 防止类似与"三次握手"中提到了的"已经失效的连接请求报文段"出现在本连接中.客户端发送完最后一个确认报文后,在这个2MSL时间中,就可以**使本连接持续的时间内所产生的所有报文段(被动关闭方延时到来的FIN报文)都从网络中消失(指的是在路由器的缓存失效),这样新的连接中不会出现旧连接的请求报文**
  - 2MSL,**最大报文生存时间**,linux中,一个MSL 30 秒,2MSL = 60s

- TIME-WAIT 状态过多会产生什么后果?怎样处理?

  - **在高并发短连接的TCP服务器上,当服务器处理完请求后主动请求关闭连接**,这样服务器上会有大量的连接处于TIME_WAIT状态,**服务器维护每一个连接需要一个socket,也就是每个连接会占用一个文件描述符,而文件描述符的使用是有上限的,如果持续高并发,会导致一些连接失败**
  - 作为服务器,短时间内关闭了大量的Client连接,就会造成服务器上出现大量的TIME_WAIT连接,**占据大量的fd,严重消耗着服务器的资源**,此时部分客户端就会显示连接不上
  - 作为客户端,短时间内大量的短连接,会大量消耗的Client机器的端口,毕竟端口只有65535个,端口被耗尽了,后续就无法在发起新的连接了
  - **解决方法**:

    - **用负载均衡来抗这些高并发的短请求**
    - **可以通过修改`/etc/sysctl.conf`配置文件中`TIME_WAIT`时间来减少此情况**
    - 服务器可以设置 **SO_REUSEADDR 套接字选项来重用 TIME_WAIT状态端口**,TIME_WAIT 状态可以通过优化服务器参数得到解决,**因为发生TIME_WAIT的情况是服务器自己可控的,要么就是对方连接的异常,要么就是自己没有迅速回收资源,总之不是由于自己程序错误导致的**
    - **利用SO_LINGER选项(设置 l_onoff为1,l_linger为0)的强制关闭方式,发送 RST 包越过TIMEWAIT状态,直接进入CLOSED状态**
    - 修改内核参数
      - 修改`/etc/sysctl.conf`,`net.ipv4.tcp_max_tw_buckets`对应的是**系统同时保持的TIME_WAIT的最大数量**,**超过此数量时,系统会立即清理出多余的TIME_WAIT连接**,系统日志中会出现TCP: time wait bucket table overflow的警告信息,最终该状态连接不会超出设置的值
      - `net.ipv4.tcp_max_tw_buckets`可设置的最大值为`262144` (硬件限制)这种方法虽然可以很快把TIME_WAIT状态数量降低至设定值以下,使用短连接连接方式的高并发状态下,TIME_WAIT产生速度非常快,当TIME_WAIT连接数达到设置值之后系统会以其产生速度相同的速度去销毁正常的TIME_WAIT连接,这时就可能出现前面说过的跳过TIME_WAIT连接状态可能会出现的结果,部分连接异常或者新的连接建立失败
      - `net.ipv4.tcp_max_tw_buckets`的值应该依据官方建议,不宜设置过小
    - 启用快速回收
      - 快速回收机制是系统对tcp连接通过一种方式进行快速回收的机制,对应内核参数中的`net.ipv4.tcp_tw_recycle`
      - **当timestamp和tw_recycle两个选项同时开启的情况下,开启per-host的PAWS机制.从而能快速回收处于TIME-WAIT状态的TCP流**
    - 开启重用机制

      - 开启重用用机制`net.ipv4.tcp_tw_reuse`,**允许将TIME-WAIT sockets重新用于新的TCP连接**,默认为0,表示关闭

      - **要开启重用机制需要依赖tcp_timestamps的功能,重用TIME_WAIT的条件是收到最后一个包后超过1s**
      - 优点:**配合tcp_timestamps可以在协议上安全的前提下对TIME_WAIT连接用于新的TCP连接,1s相比默认的60s时间还是极大的缩短了**

      - 缺点:**该机制只对"客户端"有效,即主动发起连接的一方**.比如一台web服务器,客户端发来请求时,web服务器时服务端,但web服务器又需要去连接后台数据库,这时候,web服务器又同时作为了客户端,只有主动发起连接一方主动断开所产生的TIME_WAIT该参数才生效

#### 2.3 CLOSE-WAIT状态过多原因后果及解决办法?

- 原因及后果:close_wait状态出现的原因是**被动关闭方未关闭socket造成**,可能会产生"Too many open files"的fd用尽错误
- 解决办法:
  - 设置定时器关闭超时无响应的socket连接,`read/recv`返回0,或者客户端连接socket发生`EPOLLRDHUP`事件时,关闭socket
  - 修改`/proc/sys/fs/file-max` 增大整个系统可以打开的文件数的限制
  - 修改`/etc/sysctl.conf`或`/proc/sys/net/ipv4/tcp_keepalive_time`,将keepalive的时间调小

#### 2.4 TCP计时器

TCP使用的四种计时器:

1. 重传计时器

   - 当TCP发送报文段时,就创建该特定报文段的重传计时器
   - 若在计时器截止时间到(通常60秒)之前收到了对此特定报文段的确认,则撤销此计时器
   - 若在计时器截止时间之前没有收到对此特定报文的确认,则就认为该报文丢失,需要重传此报文段,并将计时器复位

2. 坚持计时器

   - **假设TCP收到了一个窗口大小为0报文段,发送TCP就停止传送报文段,直到接收TCP发送一个非零的窗口大小**.但是这个确认有可能丢失,若确认丢了,接收TCP并不会知道,而是认为他已经完成任务了.但是发送TCP由于没有收到确认,就会一直等待接收方发送确认来通知窗口的大小.双方的TCP这时就会造成死锁,所以要使用一个计时器来避免死锁的发送
   - **当TCP收到一个窗口大小为0的确认时,就要启动坚持计时器**.当坚持计时器期限到时,发送TCP就发送一个特殊的探测报文,这个探测报文段只有一个字节数据,它有一个序号,但是它的序号永远不需要确认.探测报文段提醒对端,确认已丢失,必须重传
   - 坚持计时器的值设置为重传时间的数值.**若没有收到从接收端来的响应,需要发送一个探测报文,并将坚持计时器的值加倍和复位,直到这个值增大到门限值(通常60秒)为止**.在这以后,发送端每隔60秒发送一个探测报文,直到窗口重新打开

3. 保活计时器

   - 保活计时器用来防止两个TCP之间的连续出现长时间的空闲
   - 假定客户已主动与服务器建立了TCP链接.然后这个客户端出现故障.在这种情况下,这个链接就会永远的处于打开状态.而服务器维护一个链接,也是要耗费一定的资源的,所以必须采取措施,使服务器不能白白等下去
   - 要解决这种问题,就要对服务器设置保活计时器.每当服务器收到客户的信息,就将计时器复位,保活时间通常设置为2小时.若服务器过了两小时还没有收到客户的信息,他就发送一个探测报文,以后每隔75秒就发一次,连续发送10个探测报文后客户端仍然没有响应,服务器就认为客户端出现了故障,接着就关闭这个链接

4. 时间等待计时器
   - 当客户端进入TIME-WAIT/CLOSE-WAIT状态的时候,链接还没有释放掉,必须等待2倍的MSL(最长报文段寿命)后,客户端才能关闭连接.在时间等待期间,链接还处于一种过渡状态.这就可以使重复的FIN报文段(若果有的话)可以到达目的站因而可将其丢弃

### 99. quiz

#### 1. TCP协议如何保证可靠传输?

> [TCP协议如何保证可靠传输](https://snailclimb.gitee.io/javaguide/#/./docs/cs-basics/network/other-network-questions?id=tcp-%e5%8d%8f%e8%ae%ae%e5%a6%82%e4%bd%95%e4%bf%9d%e8%af%81%e5%8f%af%e9%9d%a0%e4%bc%a0%e8%be%93)

#### 2. 为什么要等待2MSL?

- **保证客户端发送的最后一个ACK报文能够到达服务器**,因为这个ACK报文可能丢失,服务器已经发送了FIN+ACK报文,请求断开,客户端却没有回应,于是服务器又会重新发送一次,而客户端就能在这个2MSL时间段内收到这个重传的报文,接着给出回应报文,并且会重启2MSL计时器
- 防止类似与"三次握手"中提到了的"已经失效的连接请求报文段"出现在本连接中.客户端发送完最后一个确认报文后,在这个2MSL时间中,就可以**使本连接持续的时间内所产生的所有报文段(被动关闭方延时到来的FIN报文)都从网络中消失(指的是在路由器的缓存失效),这样新的连接中不会出现旧连接的请求报文**

#### 3. time_waitd和close_wait的影响,以及如何避免?

[time_wait和close_wait](https://www.cnblogs.com/kevingrace/p/9988354.html)

#### 4. TCP最后一次ack如果客户端没有收到怎么办

如果TCP的最后一次ACK（确认）包客户端没有收到，那么发送方（通常是服务器）会认为最后的数据包没有被成功接收，因此会启动重传机制。

TCP使用了一种称为“超时重传”（Timeout Retransmission）的机制来处理这种情况。具体来说，每当TCP发送一个数据包，它都会启动一个定时器。如果在定时器到期之前没有收到ACK，TCP会认为这个数据包丢失，然后重新发送这个数据包。

这种机制确保了TCP的可靠性，即使在网络环境不稳定的情况下，TCP也能保证数据的完整性和准确性。但是，这也可能导致网络的拥塞，因此TCP还需要使用拥塞控制机制来防止网络的过度拥塞。

#### 5. 服务器出现大量close_wait的连接的原因以及解决方法

close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的,服务器出现大量close_wait状态的原因有两种:

- 服务器内部业务处理占用了过多时间,都没能处理完业务;或者还有数据需要发送;或者服务器的业务逻辑有问题,没有执行close()方法
- 服务器的父进程派生出子进程,子进程继承了socket,收到FIN的时候子进程处理但父进程没有处理该信号,导致socket的引用不为0无法回收

处理方法:

- 停止应用程序
- 修改程序里的bug

#### 6. tcpdump

- [抓包工具tcpdump](https://www.cnblogs.com/f-ck-need-u/p/7064286.html)
  以后抓包要经常用。<br>

#### 7. 为什么使用三次握手,两次握手可不可以?

如果使用两次握手的话,三次握手中的最后一次缺失,服务器不能确认客户端的接收能力.

举两个例子,第一种是黑客会伪造大量SYN请求发送给服务器,服务器立即确认并建立连接,分配资源,但是这一系列连接并不是真实存在的,这大大浪费了服务器的资源并且阻塞了正常用户的连接,这种也叫SYN洪泛攻击.第二种是服务器返回给客户端的ACK数据包可能会在传输的过程中丢失,而客户端没有收到该ACK数据包而拒绝接收服务器接下来发送的数据,于是服务器一直在发送,客户端一直在拒绝,形成死锁.

#### 8. TIME_WAIT的意义(为什么要等于2MSL)

TIME_WAIT是指四次挥手中客户端接收了服务端的FIN报文并发送ACK报文给服务器后,仍然需要等待2MSL时间的过程.虽然按道理,四个报文都发送完毕,我们可以直接进入CLOSE状态了,但是我们必须假象网络是不可靠的,有可以最后一个ACK丢失.如果客户端发送的ACK发生丢失,服务器会再次发送FIN报文给客户端,所以TIME_WAIT状态就是用来重发可能丢失的ACK报文.

#### 9. 为什么TCP挥手每两次中间有一个 FIN-WAIT2等待时间?

- 主动关闭的一端调用完close以后(即发FIN给被动关闭的一端, 并且收到其对FIN的确认ACK)则进入FIN_WAIT_2状态.**如果这个时候因为网络突然断掉/被动关闭的一段宕机等原因,导致主动关闭的一端不能收到被动关闭的一端发来的FIN(防止对端不发送关闭连接的FIN包给本端)**,这个时候就需要FIN_WAIT_2定时器, **如果在该定时器超时的时候,还是没收到被动关闭一端发来的FIN,那么直接释放这个链接,进入CLOSE状态**

#### 10. TCP是如何保证可靠传输的?

- **三次握手建立连接**(标志位):通信前确认通信实体存在,并且双方可以正确发送和接收对方的信息
- **序号机制**(序号/确认号):确保了数据是按序/完整到达
- **数据校验**(校验和):**CRC校验全部数据,保证数据完整性和正确性**
- **超时重传**(定时器):保证因链路故障未能到达数据能够被多次重发
- **窗口机制**(窗口):提供**流量控制**,避免过量发送
- **拥塞控制**:使用拥塞窗口机制,控制发送窗口大小,减少网络拥塞,避免因网络拥塞导致频繁丢包

#### 11. TCP收到RST包的几种情况

- **访问不存在的端口**
  - **试图与不被监听的端口建立连接,则直接返回RST**,同时RST报文接收通告窗口大小为0
  - 客户端向服务器的某个端口发起连接,如果端口被**处于TIME_WAIT 状态的连接占用时**,客户端也会收到RST
- **异常终止连接**
  - 一方直接发送RST报文,表示异常终止连接.**一旦发送方发送复位报文段,发送端所有排队等待发送的数据都被丢弃**.应用程序可以通过socket选项`SO_LINGER`(设置 `l_onoff`为1,`l_linger`为0)来发送RST复位报文
- **处理半打开连接**(**如果一方已经关闭或异常终止连接而另一方却还不知道,我们将这样的 TCP 连接称为半打开**(Half-Open))
  - 如A与B通信,**A关闭了连接,B却没有收到结束报文**(如网络故障),此时**B还维持着原来的连接**.而A即使重启,也没有该连接的任何信息.**这种状态就叫做半打开连接**.而此时**B往处于半打开状态的连接写数据,则对方回应RST复位报文**

#### 12. TCP keep-alive和http keep-alive的区别

- **http Keep-Alive模式**:

  - Http协议采用"请求-应答"模式,当使用普通模式,即非Keep-Alive模式时,每个请求/应答,客户端和服务器都要新建一个连接,完成之后立即断开连接;当使用Keep-Alive模式时,Keep-Alive功能使客户端到服务器端的连接持续有效,当出现对服务器的后继请求时,Keep-Alive功能避免了建立或者重新建立连接
  - http1.0中默认是关闭的,需要在http头加入"Connection: Keep-Alive",才能启用Keep-Alive
  - http 1.1中默认启用Keep-Alive,如果加入"Connection: close "才关闭.目前大部分浏览器都是用http1.1协议,也就是说默认都会发起Keep-Alive的连接请求了,所以是否能完成一个完整的Keep- Alive连接就看服务器设置情况
  - 优点:Keep-Alive模式更加高效,因为避免了连接建立和释放的开销
  - 缺点:长时间的Tcp连接容易导致系统资源无效占用,浪费系统资源

  - Keep-Alive timeout
    - Httpd守护进程,一般都提供了keep-alive timeout时间设置参数.比如nginx的keepalive_timeout,和Apache的KeepAliveTimeout.这个keepalive_timout时间值意味着:**一个http产生的tcp连接在传送完最后一个响应后,还需要hold住keepalive_timeout秒后,才开始关闭这个连接**
    - 当httpd守护进程发送完一个响应后,理应马上主动关闭相应的tcp连接,设置 keepalive_timeout后,httpd守护进程会想说:"再等等吧,看看浏览器还有没有请求过来",这一等,便是keepalive_timeout时间.**如果守护进程在这个等待的时间里,一直没有收到浏览器发过来http请求,则关闭这个http连接**

- **Tcp的Keep-alive**
  - 连接建立之后,如果客户端一直不发送数据,或者隔很长时间才发送一次数据,当连接很久没有数据报文传输时如何去确定对方还在线,到底是掉线了还是确实没有数据传输,连接还需不需要保持,这种情况在TCP协议设计中是需要考虑到的
  - TCP协议通过一种巧妙的方式去解决这个问题,**当超过一段时间之后,TCP自动发送一个数据为空的报文(侦测包)给对方,如果对方回应了这个报文,说明对方还在线,连接可以继续保持,如果对方没有报文返回,并且重试了多次之后则认为链接丢失,没有必要保持连接**
  - tcp keep-alive是TCP的一种检测TCP连接状况的保鲜机制.tcp keep-alive保鲜定时器,支持三个系统内核配置参数:
    - net.ipv4.tcp_keepalive_intvl = 15
    - net.ipv4.tcp_keepalive_probes = 5
    - net.ipv4.tcp_keepalive_time = 7200
  - keepalive是TCP保鲜定时器,当网络两端建立了TCP连接之后,闲置(双方没有任何数据流发送往来)了tcp_keepalive_time后,服务器就会尝试向客户端发送侦测包,来判断TCP连接状况(有可能客户端崩溃/强制关闭了应用/主机不可达等等)
  - 如果没有收到对方的回答(ack包),则会在tcp_keepalive_intvl后再次尝试发送侦测包,直到收到对方的ack,如果一直没有收到对方的ack,一共会尝试 tcp_keepalive_probes次,每次的间隔时间在这里分别是15s, 30s, 45s, 60s, 75s.如果尝试tcp_keepalive_probes,依然没有收到对方的ack包,则会丢弃该TCP连接.**TCP连接默认闲置时间是2小时,一般设置为30分钟足够了**

#### 13. 当保持长连接时,如何判断一次请求已经完成?

- Content-Length:表示实体内容的长度.浏览器通过这个字段来判断当前请求的数据是否已经全部接收.所以,当浏览器请求的是一个静态资源时,即服务器能明确知道返回内容的长度时,可以设置Content-Length来控制请求的结束.**但当服务器并不知道请求结果的长度时,如一个动态的页面或者数据,Content-Length就无法解决上面的问题,这个时候就需要用到Transfer-Encoding字段**
- Transfer-Encoding:**指传输编码**,在上面的问题中,当服务端无法知道实体内容的长度时,就可以通过指定Transfer-Encoding: chunked来告知浏览器当前的编码是将数据分成一块一块传递的.当然, 还可以指定`Transfer-Encoding: gzip, chunked`表明实体内容不仅是gzip压缩的,还是分块传递的.最后,**当浏览器接收到一个长度为0的chunked时**, 知道当前请求内容已全部接收

#### 14. TCP和UDP是否可以绑定同一端口进行通信?

- 网络中可以被命名和寻址的通信端口,是操作系统可分配的一种资源
- 按照OSI七层协议的描述,传输层与网络层在功能上的最大区别是传输层提供进程通信能力.从这个意义上讲,网络通信的最终地址就不仅仅是主机地址了,还包括可以描述进程的某种标识符.为此,TCP/IP协议提出了协议端口(protocol port,简称端口)的概念,用于标识通信的进程
- **端口是一种抽象的软件结构(包括一些数据结构和I/O缓冲区)**.应用程序(即进程)通过系统调用与某端口建立连接(binding)后,传输层传给该端口的数据都被相应进程所接收,相应进程发给传输层的数据都通过该端口输出.**在TCP/IP协议的实现中,端口操作类似于一般的I/O操作,进程获取一个端口,相当于获取本地唯一的I/O文件,可以用一般的读写原语访问之**
- **类似于文件描述符,每个端口都拥有一个叫端口号(port number)的整数型标识符,用于区别不同端口**.**由于TCP/IP传输层的两个协议TCP和UDP是完全独立的两个软件模块,因此各自的端口号也相互独立,如TCP有一个255号端口,UDP也可以有一个255号端口,二者并不冲突**
- 端口号的分配是一个重要问题.**有两种基本分配方式**:
  - 第一种叫全局分配,这是一种集中控制方式,由一个公认的中央机构根据用户需要进行统一分配,并将结果公布于众
  - 第二种是本地分配,又称动态连接,即进程需要访问传输层服务时,向本地操作系统提出申请,操作系统返回一个本地唯一的端口号,进程再通过合适的系统调用将自己与该端口号联系起来(绑扎)
- TCP/IP端口号的分配中综合了上述两种方式.TCP/IP将端口号分为两部分,少量的作为保留端口,以全局方式分配给服务进程.因此,每一个标准服务器都拥有一个全局公认的端口(即周知口,well-known port),即使在不同机器上,其端口号也相同.剩余的为自由端口,以本地方式进行分配.TCP和UDP均规定,小于256的端口号才能作保留端口
