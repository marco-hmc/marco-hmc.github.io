---
layout: post
title: 并发编程
categories: language
related_posts: True
tags: cpp 并发编程
toc:
  sidebar: left
---

## 并发编程

并发编程是指在同时执行多个任务或线程，使得这些任务或线程可以在同一时间段内交替执行，从而提高程序的执行效率和资源利用率。

在单机编程中，并发编程的手段主要有这三种

- 多线程
- 多进程
- 异步编程（协程）

### 1. 进程和线程的概念

#### 1.0 进程和线程的状态

在操作系统中，进程和线程的状态是一样的，通常有以下几种状态：

1. **新建（New）**：进程/线程正在被创建。
2. **就绪（Ready）**：进程/线程已经创建并等待被分配 CPU 时间片。
3. **运行（Running）**：进程/线程正在执行。
4. **等待（Waiting）或阻塞（Blocked）**：进程/线程正在等待某个事件（如 I/O 操作完成或资源可用）。
5. **终止（Terminated）或完成（Completed）**：进程/线程已经完成执行或被终止。

- **进程状态转换图**

以下是一个简单的进程状态转换图：

```
        +-------+       +-------+
        | New   |  ->   | Ready |
        +-------+       +-------+
                          ^  |
                          |  v
        +-----------------------+
        |       Running         |
        +-----------------------+
            |  ^             |
            v  |             v
        +-------+        +-------+
| waiting/Blocked|       | Terminated|
        +-------+        +-------+
```

#### 1.1 进程线程的调度

在 Linux 中，调度的基本单位是线程（也称为轻量级进程，LWP）。每个线程被视为一个独立的调度实体，操作系统的调度器会选择一个线程来运行。

- **调度方法**

Linux 使用完全公平调度器（CFS）作为默认的调度器。CFS 旨在提供公平的 CPU 时间分配，以下是一些常见的调度方法：

1. **完全公平调度器（CFS）**：

   - CFS 是 Linux 的默认调度器，旨在提供公平的 CPU 时间分配。
   - CFS 使用红黑树数据结构来管理可运行的任务，并根据任务的虚拟运行时间进行调度。

2. **实时调度器**：

   - Linux 还支持实时调度策略，包括 SCHED_FIFO 和 SCHED_RR。
   - SCHED_FIFO：先进先出调度策略，优先级高的任务先运行，直到任务主动放弃 CPU 或被更高优先级的任务抢占。
   - SCHED_RR：轮转调度策略，与 SCHED_FIFO 类似，但每个任务有一个固定的时间片，时间片用完后任务被放到队列末尾。

3. **批处理调度器**：

   - SCHED_BATCH：适用于批处理任务，调度器会尽量减少这些任务对交互性任务的影响。

4. **空闲调度器**：

   - SCHED_IDLE：适用于最低优先级的任务，只有在系统空闲时才会运行这些任务。

---

- **优先级设定**

Linux 中的调度优先级分为两类：实时优先级和普通优先级。

1. **实时优先级**：

   - 实时优先级范围为 1 到 99，数值越大优先级越高。
   - 可以使用 `sched_setscheduler` 系统调用来设置实时优先级。

2. **普通优先级**：

   - 普通优先级范围为 -20 到 19，数值越小优先级越高。
   - 可以使用 `nice` 和 `renice` 命令来调整普通优先级。

#### 1.2 进程和线程的区别

- **进程**

  1.  **定义**：
      - 进程是操作系统中资源分配的基本单位。每个进程都有自己独立的地址空间、内存、文件描述符等资源。
  2.  **资源**：
      - 进程拥有独立的资源，包括内存空间、文件描述符、全局变量等。
      - 进程之间的资源是相互隔离的，一个进程不能直接访问另一个进程的资源。
  3.  **开销**：
      - 进程的创建和销毁开销较大，因为需要分配和回收大量的系统资源。
      - 进程之间的上下文切换开销也较大，因为需要保存和恢复独立的内存空间和资源。
  4.  **通信**：
      - 进程之间的通信需要通过进程间通信（IPC）机制，如管道、消息队列、共享内存、信号等。
      - 进程间通信相对复杂，开销较大。

- **线程**

  1.  **定义**：
      - 线程是操作系统中调度的基本单位。一个进程可以包含多个线程，线程共享进程的资源。
  2.  **资源**：
      - 线程共享进程的资源，包括内存空间、文件描述符、全局变量等。
      - 线程之间可以直接访问共享的资源，通信和同步相对简单。
  3.  **开销**：
      - 线程的创建和销毁开销较小，因为线程共享进程的资源。
      - 线程之间的上下文切换开销也较小，因为不需要切换独立的内存空间和资源。
  4.  **通信**：
      - 线程之间的通信可以通过共享内存和同步机制（如互斥锁、条件变量等）实现。
      - 线程间通信相对简单，开销较小。

#### 1.3 线程之间私有和共享的资源有哪些?

线程之间的私有和共享资源主要包括以下几种：

**私有资源**：

1. **栈内存**：每个线程都有自己的栈内存，用于存储局部变量和函数调用的上下文信息。其他线程无法访问一个线程的栈内存。

2. **寄存器**：每个线程都有自己的寄存器集，包括程序计数器和其他寄存器。这些寄存器的值在线程切换时会被保存和恢复。

3. **线程局部存储（Thread Local Storage，TLS）**：这是一种特殊的机制，允许每个线程拥有自己的全局变量或静态变量的副本。

**共享资源**：

1. **堆内存**：所有线程共享同一块堆内存，线程可以创建对象并将其地址传递给其他线程。

2. **全局变量和静态变量**：全局变量和静态变量存储在所有线程共享的内存中，任何线程都可以访问它们。

3. **文件和网络资源**：如果一个程序打开了一个文件或网络连接，所有的线程都可以使用这些资源。

请注意，虽然线程可以共享许多资源，但在访问这些资源时需要小心，因为这可能会导致竞态条件和其他并发问题。为了避免这些问题，通常需要使用互斥锁、信号量等同步机制来保护共享资源。

#### 5.1 进程、线程和协程的对比：

- 进程切换的开销有哪些？

  - 地址空间的转换，如切换页表全局目录，刷新TLB（Translation Lookaside Buffer，快表）。
  - 硬件上下文切换，如切换内核栈，载入寄存器数据。
  - 保存和恢复进程状态，包括程序计数器，虚拟内存信息等。
  - 操作系统需要在用户态和内核态之间切换，这也会带来额外的开销。

- 线程切换的开销有哪些？

  - 线程切换的开销大体与进程一致，但相对较小，因为所有线程共享同一地址空间，所以不需要进行地址空间的转换。
  - 硬件上下文切换，如切换内核栈，载入寄存器数据。
  - 保存和恢复线程状态，包括程序计数器，栈指针等。
  - 由于线程切换不需要切换地址空间，所以CPU Cache命中率更高，不需要频繁更新。

- 协程切换的开销有哪些？
  - 协程切换的开销非常小，因为协程是在用户态进行切换，不需要进行系统调用，也不需要切换地址空间和保存恢复大量的硬件上下文。
  - 协程切换主要涉及的是程序计数器，栈指针等少量数据的保存和恢复。
  - 由于协程是在同一线程中切换，所以CPU Cache命中率非常高。

#### 98. supplement

上面的讨论主要是单机情况，但是对于多机情况来说，并发编程的核心思路是将任务拆分后分发到多台机器上独立处理，再通过网络通信（如 RPC、消息队列等）实现协调与同步，同时利用分布式锁、负载均衡和容错机制保证数据一致性和系统稳定性。

并发编程四种模型的核心区别与应用场景解析
一、模型核心机制对比

1. ‌多线程模型‌
   ‌核心机制‌：
   通过创建共享同一进程内存空间的多个执行流实现并发，依赖锁、信号量等同步机制控制资源竞争‌。
   ‌区别性特征‌：
   线程间共享内存，需显式同步（如互斥锁）避免数据竞争‌
   受全局解释器锁（GIL）限制（如Python），无法真正并行执行‌
   ‌应用场景‌：
   I/O密集型任务（如Web服务器处理HTTP请求）‌
   GUI应用中的异步响应（如后台下载与界面操作分离）‌

2. ‌多进程模型‌
   ‌核心机制‌：
   通过操作系统创建多个独立进程，每个进程拥有独立内存空间和资源，通过进程间通信（IPC）交换数据‌。
   ‌区别性特征‌：
   进程间资源隔离，天然避免数据竞争‌
   创建和切换开销显著高于线程（约10倍）‌
   ‌应用场景‌：
   计算密集型任务（如数值模拟、图像渲染）‌
   需要高稳定性的服务（如进程崩溃不影响其他任务）‌

3. ‌异步编程/协程模型‌
   ‌核心机制‌：
   基于事件循环和非阻塞I/O，通过协程的挂起/恢复实现单线程内高并发‌。
   ‌区别性特征‌：
   协程切换在用户态完成，无需内核介入，性能优于线程‌
   通过async/await语法实现同步式编码风格‌
   ‌应用场景‌：
   高并发网络服务（如WebSocket实时通信）‌
   大规模I/O密集型任务（如爬虫批量请求）‌

多线程、多进程与协程的操作系统级对比
一、调度机制与操作系统介入程度

1. ‌多进程‌
   ‌调度机制‌：
   由操作系统内核直接管理，进程上下文切换涉及‌完整地址空间切换‌（包括页表、文件描述符、寄存器等），触发完整的‌内核态切换‌‌
   ‌开销特征‌：
   每次切换消耗约‌1-10微秒‌（需刷新TLB、保存恢复内存映射等），占用CPU资源高‌
2. ‌多线程‌
   ‌调度机制‌：
   线程作为进程的子单元，共享同一地址空间。操作系统内核通过‌时间片轮转‌进行抢占式调度，切换时仅保存线程私有栈和寄存器‌
   ‌开销特征‌：
   切换耗时约‌0.1-1微秒‌（无地址空间切换），但需要经过内核态中断（如系统调用）‌

3. ‌协程‌
   ‌调度机制‌：
   完全在‌用户态实现‌，由程序员通过代码显式控制切换点（如yield或await），操作系统不感知协程存在‌
   ‌开销特征‌：
   切换仅需保存少量寄存器（如PC指针、栈指针），耗时约‌10-100纳秒‌，无内核态切换‌

二、资源管理对比
维度 多进程 多线程 协程
‌地址空间‌ 独立（隔离性强）‌ 共享进程空间‌ 共享线程栈‌
‌通信方式‌ IPC（管道/共享内存）‌ 共享内存+锁‌ 无锁数据传递‌
‌CPU核心利用‌ 可跨核心并行‌ 受GIL限制（如Python）‌ 单核并发‌
‌容错性‌ 进程崩溃不影响其他‌ 线程崩溃导致进程终止‌ 协程异常需手动处理‌

三、操作系统调度器交互模式

1. ‌进程调度‌（操作系统层）
   通过‌进程控制块(PCB)‌维护状态，包含内存映射表、文件描述符表等元数据‌
   触发调度时机：时间片耗尽、系统调用阻塞、硬件中断等‌
2. ‌线程调度‌（内核层）
   通过‌线程控制块(TCB)‌管理，仅包含栈指针、寄存器等轻量信息‌
   内核维护‌全局线程队列‌，执行优先级调度算法（如CFS）‌
3. ‌协程调度‌（用户层）
   无内核数据结构支持，由‌用户态调度器‌（如事件循环）维护协程队列‌
   切换完全避开内核中断，通过函数跳转直接执行目标协程代码‌
   四、典型性能瓶颈场景
4. ‌多进程瓶颈‌
   ‌进程间通信开销‌：管道/消息队列的序列化与拷贝操作（如传输1GB数据需完整内存复制）‌
   ‌上下文切换抖动‌：高频进程切换导致CPU利用率下降（如每秒切换10万次时，50%时间消耗在切换）‌
5. ‌多线程瓶颈‌
   ‌锁竞争‌：共享资源导致大量线程阻塞在互斥锁/信号量上（如Python GIL引发的伪并发）‌
   ‌内核调度延迟‌：线程数超过CPU核心数时，时间片轮转引发延迟波动（如10,000线程导致调度延迟>1ms）‌
6. ‌协程瓶颈‌
   ‌CPU计算阻塞‌：协程内执行长耗时计算会阻塞整个线程（如单线程内10万协程执行矩阵运算）‌
   ‌系统调用阻塞‌：同步I/O操作（如未改造为异步的磁盘读写）导致事件循环停滞‌
   五、核心结论
   ‌调度开销排序‌：
   进程切换 > 线程切换 > 协程切换（数量级差异）‌
   ‌操作系统介入深度‌：
   进程需完整内核支持 → 线程依赖内核调度器 → 协程完全用户态驱动‌
   ‌适用场景选择‌：
   ‌多进程‌：计算密集型 + 高隔离需求（如科学计算）‌
   ‌多线程‌：I/O密集型 + 数据共享需求（如Web服务器）‌
   ‌协程‌：超高并发I/O + 低延迟要求（如实时通信服务）‌
