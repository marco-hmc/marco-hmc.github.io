---
layout: post
title: c++的多线程
categories: language
related_posts: True
tags: cpp 并发编程 multiThread
toc:
  sidebar: left
---

## c++的多线程

多线程的使用可以从两个角度出发：

- 多线程的创建和相关管理手段
- 多线程的通信和同步方式

* cpu 的单核性能提升接近瓶颈，多核是未来 cpu 的趋势。
* 因为缓存同步开销、资源竞争问题，n 核机器的性能是做不到是单核机器的 n 倍，但如何让性能接近 n 倍是一直在研究的。
* 并发和并行的区别：

  - 并发：追求的是提升处理个数能力，是要异步，单核场景下，多线程也是有意义。
  - 并行：追求的是提升处理能力，是要速度，单核场景下，多线程无意义。

* 线程和任务要区分：
  在性能要要求的场景下，线程是复用的，是固定的，是常驻的；
  任务才是可被消费的。
  因此 tbb 和线程池的处理对象，或者说接受的输入对象都是 task。

### 0. 多线程的概念

- **线程的优缺点**
  线程是进程内的执行单元，是操作系统进行调度的基本单位。一个进程中可以包含多个线程，它们共享进程的内存空间，因此线程间的通信更为方便。但是，多线程编程需要处理好同步和互斥，以避免数据竞争和死锁等问题。

  - 优点
    - 线程创建快，上下文切换快，创建开销小
    - 线程通信快
  - 缺点
    - 要考虑锁机制，代码写起来麻烦
    - 不可靠，一个线程挂了，全挂了

- **什么是线程安全？**
  简单来说就是，多线程一般是在同一个进程空间，共享内存空间。
  因此多线程同时对一个变量操作的时候，就会出现安全问题。

  - 简单理解，确保在多线程访问的时候，我们的程序还能按照我们预期的行为去执行，那么就是线程安全
    线程安全的定义可以总结为以下几点：

  1. **正确性**：在多线程环境下，多个线程同时访问同一个对象时，程序的行为和结果是正确的，不会出现数据不一致或程序崩溃的情况。
  2. **原子性**：操作是不可分割的，要么全部执行，要么全部不执行，不会被其他线程的操作中断。
  3. **可见性**：一个线程对共享变量的修改对其他线程是可见的。
  4. **有序性**：程序的执行顺序按照代码的先后顺序执行，不会因为指令重排序导致意外的行为。

- **怎么实现线程安全**

  1. **使用锁（Mutex）**：通过互斥锁（`std::mutex`）来保护共享数据，确保同一时间只有一个线程可以访问或修改数据。
  2. **使用原子操作（Atomic Operations）**：使用原子操作（`std::atomic`）来保证操作的原子性，不需要显式使用锁。
  3. **使用线程本地存储（Thread Local Storage）**：为每个线程分配独立的数据，避免多个线程访问同一个共享数据。
  4. **无锁数据结构（Lock-Free Data Structures）**：使用无锁数据结构，如无锁队列，避免使用锁来实现线程安全。

- **什么是可重入函数**
  可重入函数是指在任何时刻都可以安全地被中断，并且在中断后可以安全地重新进入执行的函数。具体来说，可重入函数具有以下特性：

  1. **可以被中断**：函数可以在执行过程中被中断，并且在中断后可以安全地重新进入执行。
  2. **不依赖外部环境**：函数除了使用自己栈上的变量外，不依赖于任何外部环境（包括静态变量和全局变量）。这样的函数被称为纯代码（pure code）可重入函数，可以允许多个副本同时运行，因为它们使用的是独立的栈，不会互相干扰。
     简单来说，可重入函数只使用自己栈上的数据，不使用静态变量、全局变量或类成员变量。如果调用的子函数也只使用自己栈上的数据，那么这个函数就是可重入的。

- **可重入函数的特点**

  1. 不在函数内部使用静态或全局数据。
  2. 不返回静态或全局数据，所有数据都由函数的调用者提供。
  3. 不调用不可重入函数。
  4. 没有锁
  5. 这些情况也是不可重入的
  6. **使用静态数据结构**：例如 `getpwnam` 和 `getpwuid`。如果信号发生时正在执行 `getpwnam`，信号处理程序中执行 `getpwnam` 可能会覆盖原来 `getpwnam` 获取的旧值。
  7. **调用 `malloc` 或 `free`**：如果信号发生时正在执行 `malloc`（修改堆上存储空间的链接表），信号处理程序又调用 `malloc`，会破坏内核的数据结构。
  8. **使用标准 IO 函数**：许多标准 IO 的实现都使用全局数据结构，例如 `printf`（文件偏移是全局的）。
  9. **调用 `longjmp` 或 `siglongjmp`**：如果信号发生时程序正在修改一个数据结构，处理程序返回到另外一处，可能会导致数据被部分更新。

- **可重入函数的意义是什么？**

  1. **信号处理程序**：

  - 信号处理程序是处理异步信号的函数。当程序运行时，如果接收到某个信号（如 `SIGINT`、`SIGTERM` 等），操作系统会中断当前的执行流，转而执行信号处理程序。由于信号处理程序可以在任何时候被调用，因此它们必须是可重入的，以避免在中断时修改共享数据导致的数据不一致或程序崩溃。

  2. **中断处理程序**：

  - 在嵌入式系统或操作系统内核中，中断处理程序用于处理硬件中断。中断处理程序可以在任何时候被调用，因此它们也必须是可重入的，以确保在中断时不会破坏系统的稳定性。

  3. 可重入函数一般是信号函数相关的概念。而无论单线程还是多线程，‌被中断的线程/进程必须等待信号处理函数结束‌，才能回到原执行点。多线程的优势仅体现在未被中断的线程可以继续运行。
     可重入函数就不能上锁，因为可重入函数基本指的就是信号处理函数，信号处理函数有非常高得优先级，如果有锁，且拿不到锁，就很容易卡死了，因为不会轻易让出线程，破坏了执行流。

- **可重入函数和线程安全的联系是什么**
  - **可重入函数**是线程安全函数的一个子集。可重入函数在任何时刻都可以安全地被中断，并且在中断后可以安全地重新进入。
  - **线程安全函数**可以通过使用锁来保护共享数据，但使用锁的函数在被中断后重新进入时可能会导致死锁或其他同步问题。
  - 线程安全函数可以使用静态或全局数据，只要这些数据受到适当的保护，但可重入函数不能使用静态或全局数据。
  - 线程安全函数可以调用其他线程安全但不可重入的函数，但可重入函数不能调用不可重入的函数。

### 1. 多线程的创建和管理手段

- **1. `std::thread`**

  - **适用场景**：
    - **需要直接控制线程的生命周期**：当你需要精细控制线程的创建、启动、暂停、恢复和终止时，使用 `std::thread` 是合适的选择。
    - **需要共享资源的复杂同步**：当多个线程需要访问共享资源，并且需要复杂的同步机制（如互斥锁、条件变量）时，`std::thread` 提供了更大的灵活性。
    - **需要高性能**：在某些高性能计算场景中，直接使用 `std::thread` 可以避免一些抽象层带来的开销。

- **2. `std::async`**

  - **适用场景**：
    - **简单的异步任务**：当你需要启动一个简单的异步任务，并且不需要显式管理线程时，使用 `std::async` 是最方便的选择。
    - **任务的启动策略**：当你希望任务可以根据需要立即执行或延迟执行时，`std::async` 提供了灵活的启动策略（如 `std::launch::async` 和 `std::launch::deferred`）。
    - **需要返回值的异步任务**：当你需要启动一个异步任务并获取其返回值时，`std::async` 会返回一个 `std::future` 对象，方便获取结果。

- 3. `std::packaged_task`\*\*
  - **适用场景**：
    - **需要更高的灵活性**：当你需要将任务与线程分离，并在不同的时间和上下文中启动任务时，使用 `std::packaged_task` 是合适的选择。
    - **复杂的任务管理**：当你需要显式管理任务的生命周期，并且可能需要将任务传递给其他线程或存储在容器中时，`std::packaged_task` 提供了更高的灵活性。
    - **需要返回值的任务**：与 `std::async` 类似，`std::packaged_task` 也会返回一个 `std::future` 对象，用于获取任务的结果。

如果用一句话总结区别的话就是，不需要线程返回结果就是用`std::thread`，需要线程返回结果就是用`async`和`packaged_task`；不想管理线程的，就是用`async`，想提升性能去管理线程的话，就是`packaged_task`和`std::thread`。

#### 1.1 thread

- **特点**

  - **直接控制**：`std::thread` 提供了对线程的直接控制，可以精细地管理线程的创建、执行和销毁。
  - **手动管理**：需要手动管理线程的生命周期，包括创建、等待（`join`）和分离（`detach`）线程。
  - **无返回值**：`std::thread` 无法直接返回任务的结果，需要使用其他同步机制（如 `std::promise` 和 `std::future`）来获取结果。

- **`join`定义**

  - 当你调用 `join` 时，它会等待被调用线程执行完毕，然后再继续执行主线程。换句话说，`join` 使得主线程等待被调用线程的完成。
  - 使用 `join` 可以确保在主线程继续执行之前，被调用线程的任务已经完成。这对于需要等待线程执行结果的情况很有用。

- **`detach`定义**
  - 当你调用 `detach` 时，它使得被调用线程成为后台线程，与主线程分离。主线程不再等待被调用线程的完成。
  - 使用 `detach` 可以使得主线程在后台线程运行的同时继续执行，而不必等待后台线程完成。这对于一些异步任务或长时间运行的任务很有用。

#### 1.2 async

`std::async` 是一个强大的工具，是 C++11 中引入的一个用于启动异步任务的函数。通过合理使用 `std::async` 和选择适当的启动策略，可以提高程序的并发性能和响应速度。它自动处理线程的创建和销毁，使得异步编程变得更简单。如果你只需要在后台运行一个任务并获取其结果，那么`std::async`通常是最好的选择。

- **特点**

  - - **自动管理**：`std::async` 提供了一个简单的接口来启动异步任务，并自动管理线程的生命周期。
  - - **返回 `std::future`**：`std::async` 返回一个 `std::future` 对象，通过这个对象可以获取异步任务的结果。
  - - **启动策略**：可以指定启动策略（`std::launch::async` 或 `std::launch::deferred`），决定任务是立即异步执行还是延迟到调用 `get` 时执行。

- **应用场景**
  - - **简单异步任务**：适用于简单的异步任务，不需要复杂的线程管理。
  - - **自动管理需求**：适用于希望自动管理线程生命周期的场景，减少手动管理的复杂性。
  - 多为同步计算和异步计算同时存在的场景。或者更进一步，用来处理io耗时而非cpu密集任务的。比如说要播放一个特效动画，然后计算伤害，特效动画开一个async去做，后面继续计算等等。

```cpp
  template <class Fn， class... Args>
  std::future<typename std::result_of<Fn(Args...)>::type>
      async(std::launch policy， Fn&& f， Args&&... args);
```

- **参数及其意义**

  1. **`policy`**：异步任务的启动策略，是一个 `std::launch` 类型的枚举值。可能的值有：

  - `std::launch::async`：异步执行任务，可能会在新的线程中执行。
  - `std::launch::deferred`：
    延迟执行任务，直到调用 `std::future` 对象的 `get` 或 `wait` 函数时执行，可能在当前线程执行。
  - `std::launch::async | std::launch::deferred`：由系统自行选择执行方式，可能异步也可能延迟。

  2. **`f`**：要异步执行的函数或可调用对象。
  3. **`args...`**：传递给函数 `f` 的参数列表。

- **返回值**
  `std::async` 返回一个 `std::future` 对象，通过这个对象可以获取异步任务的结果。`std::future` 是一个轻量级的异步结果管理器，提供了对异步任务的状态查询（是否完成/是否有异常等）以及获取最终结果的功能。

- **注意事项**
  - 使用 `std::async` 可以方便地在后台执行任务，而调用 `get` 函数时，如果任务尚未完成，主线程会等待直到任务完成。这有助于充分利用多核系统的性能，将计算密集型任务分配到不同的线程中执行。
  - 在使用 `std::async` 时，需要小心选择适当的启动策略，以避免不必要的线程创建和上下文切换。

#### 1.3 packaged_task

`std::packaged_task` 是 C++11 中引入的一个类模板，用于将一个可调用对象（`task`，如函数、lambda 表达式或函数对象）包装成任务，并将其结果存储在一个 `std::future` 对象中，以便稍后获取。

- **特点**

  - **任务包装**：`std::packaged_task` 将一个可调用对象（如函数、lambda 表达式或函数对象）包装成任务，并将其结果存储在一个 `std::future` 对象中。
  - **灵活性和控制**：提供了更多的灵活性，但也需要更多的管理工作。需要自己创建一个 `std::thread` 并将 `std::packaged_task` 对象传递给它。
  - **与 `std::future` 关联**：`std::packaged_task` 自动与 `std::future` 关联，简化了结果获取的过程。
  - 应该将`std::packaged_task`理解成原来传递给`std::thread`的`func`的封装。`std::thread`是os层面涉及线程调度的事情，`std::packaged_task`则是业务层面对调度对象的操作。

- **应用场景**
  - **复杂任务管理**：适用于需要将任务与 `std::future` 关联的复杂场景。
  - **线程池实现**：适用于实现线程池等需要精细控制任务调度和执行的场景。
  - 当需要对多线程直接复杂管理的时候，因为线程没有返回值，而且什么时候开始运行也不好控制，这个时候一般就用packaged_task。因此一般线程池都是用这个。

* **主要特点**
  1. **任务包装**：
  - `std::packaged_task` 只是对一个任务类型的包装。经过包装之后的 `packaged_task` 返回值为 `future` 类型。
  - `future` 是对结果的一个包装，只有调用 `future::get()` 方法时，任务才会真正执行并返回结果。
  2. **灵活性和控制**：
  - `std::packaged_task` 提供了更多的灵活性，但也需要更多的管理工作。
  - 它只是将一个任务和一个 `std::future` 对象关联起来，并不创建线程。需要自己创建一个 `std::thread` 并将 `std::packaged_task` 对象传递给它。
  - 这使得可以更精细地控制线程的创建和销毁，以及任务的调度。例如，可以将任务提交给一个线程池，或者在特定的时间点启动线程。

### 2. 多线程间的通信、同步手段

相较于进程，线程是共享同一进程的地址空间的，线程间的通信将会很容易，直接就可以通过全局变量来交换数据。但这种访问的便利性也带来了一些风险，通常当有多个线程访问相同的共享数据时，做出的操作往往是不安全的。这就需要线程同步。所谓的线程同步，就是指多线程通过特定的设置（如互斥量、事件对象、临界区）来控制线程之间的执行顺序。

同步的目的是协同、协助、互相配合线程的运行，而不是同时进行。例如，一个线程完成任务后，另一个线程才开始执行。线程同步通过建立线程之间的执行顺序关系，确保线程按预定的顺序运行。如果没有同步机制，线程将各自独立运行，可能导致资源竞争和数据不一致的问题。

下面介绍c++中支持的常见同步手段。

- **1. `std::mutex`**

  - **适用场景**：
    - **互斥锁**：当你需要确保只有一个线程可以访问共享资源时，使用 `std::mutex` 是合适的选择。
  - **解释**：
    - `std::mutex` 提供了互斥锁，确保只有一个线程可以访问共享资源。
    - 使用 `std::lock_guard` 自动管理锁的生命周期，避免死锁。

- **2. `std::condition_variable`**

  - **适用场景**：
    - **条件变量**：当你需要线程间的同步和通信时，使用 `std::condition_variable` 是合适的选择。
  - **解释**：
    - `std::condition_variable` 提供了条件变量，用于线程间的同步和通信。
    - 一个线程等待条件变量，另一个线程设置条件并通知等待的线程。

- **3. `std::promise` 和 `std::future` / `std::shared_future`**

  - **适用场景**：
    - **线程之间的值传递**：当你需要在线程之间传递值时，使用 `std::promise` 和 `std::future` 是合适的选择。
  - **解释**：
    - `std::promise` 用于设置值，`std::future` 用于获取值。
    - 在一个线程中设置值，在另一个线程中获取值，实现线程间的值传递。

- **4. `std::atomic`**
  - **适用场景**：
    - **原子操作**：当你需要进行原子操作以确保线程安全时，使用 `std::atomic` 是合适的选择。
  - **解释**：
    - `std::atomic` 提供了原子操作，确保多个线程对共享变量的操作是线程安全的。
    - 在多个线程中对 `std::atomic` 变量进行操作，避免数据竞争。

#### 2.1 互斥锁

##### 2.1.1 c++标准库直接支持的锁类型

- **`std::mutex`**：基本的互斥锁。
- **`std::recursive_mutex`**：递归互斥锁，允许同一线程多次获取锁。
- **`std::shared_mutex`**：读写锁，允许多个线程同时读取，但写入时需要独占锁。
- **`std::timed_mutex`**：带有超时功能的互斥锁。
- **`std::shared_timed_mutex`**：带有超时功能的共享互斥锁。

##### 2.1.2 锁策略/锁管理/上锁方式

- **`std::lock`**

  - **功能**：一个函数模板，用于使用死锁避免算法锁定多个可锁对象。
  - **特点**：确保多个锁按顺序锁定，避免死锁。
  - **使用场景**：适用于需要同时锁定多个互斥锁的场景，确保线程安全。
  - **如何使用**：
  - 调用 `std::lock` 函数时传入多个互斥锁，使用死锁避免算法锁定所有互斥锁。
  - 在锁定成功后，可以使用 `std::unique_lock` 或 `std::lock_guard` 管理这些锁。

- **`std::try_lock`**

  - **功能**：一个函数模板，尝试获取多个互斥锁的所有权，如果无法获取则返回。
  - **特点**：用于尝试锁定多个互斥锁，而不会阻塞线程。
  - **使用场景**：适用于需要尝试锁定多个互斥锁的场景，避免线程阻塞。
  - **如何使用**：
  - 调用 `std::try_lock` 函数时传入多个互斥锁，尝试获取所有互斥锁的所有权。
  - 如果成功获取所有互斥锁，返回 -1；如果无法获取某个互斥锁，返回该互斥锁的索引。

- **`std::unique_lock`**

  - **功能**：提供更多灵活性和控制的锁管理类，可以延迟锁定、手动锁定和解锁、传递锁的所有权。
  - **特点**：适用于复杂的锁定需求，支持延迟锁定和手动解锁。
  - **使用场景**：适用于需要灵活控制锁定和解锁的场景，如需要在不同函数间传递锁的所有权。
  - **如何使用**：
  - 创建 `std::unique_lock` 对象时可以选择立即锁定或延迟锁定互斥锁。
  - 可以手动调用 `lock` 和 `unlock` 方法来控制锁定和解锁。
  - 可以将 `std::unique_lock` 对象传递给其他函数，传递锁的所有权。

- **`std::lock_guard`**

  - **功能**：简单的 RAII 风格的锁管理类，在构造时自动锁定互斥锁，在析构时自动解锁互斥锁。
  - **特点**：适用于基本的锁定需求，确保在作用域结束时自动释放锁。
  - **使用场景**：适用于简单的临界区保护，确保在函数退出时自动释放锁。
  - **如何使用**：
  - 创建 `std::lock_guard` 对象时传入互斥锁，自动锁定互斥锁。
  - 在作用域结束时，`std::lock_guard` 会自动解锁互斥锁。

- **`std::scoped_lock`**
  - **功能**：同时锁定多个互斥锁，并在作用域结束时自动解锁。
  - **特点**：RAII 风格的锁管理器，确保在作用域结束时自动释放锁，避免死锁和资源泄漏。
  - **使用场景**：适用于需要同时锁定多个互斥锁的场景，确保线程安全。
  - **如何使用**：
  - 创建 `std::scoped_lock` 对象时传入多个互斥锁。
  - 在作用域结束时，`std::scoped_lock` 会自动解锁所有互斥锁。

##### 2.1.3 未支持的锁类型/其他锁概念

- **自旋锁（Spin Lock）**

  - **功能**：自旋锁在等待锁时会不断循环检查锁的状态，而不是阻塞线程。
  - **特点**：适用于高频率锁定和解锁的场景，避免线程上下文切换的开销。
  - **使用场景**：适用于锁持有时间短、频繁加锁解锁的场景，如短时间的临界区保护。
  - **如何实现**：通常使用原子操作（如 `std::atomic_flag`）实现，通过不断尝试获取锁来实现自旋。

- **分段锁（Segmented Locks）**

  - **功能**：将资源分割成多个部分，并对每个部分使用单独锁的机制，以减少锁竞争。
  - **特点**：通过分段锁减少锁竞争，提高并发性能。
  - **使用场景**：适用于需要对大块资源进行并发访问的场景，如哈希表、缓存等。
  - **如何实现**：将资源分割成多个部分，每个部分使用单独的锁，线程只锁定需要访问的部分。

- **票据锁（Ticket Locks）**

  - **功能**：先来先服务的锁机制，通过发放票据来控制对资源的访问顺序。
  - **特点**：确保公平性，先请求锁的线程先获得锁。
  - **使用场景**：适用于需要严格控制访问顺序的场景，确保公平性。
  - **如何实现**：使用两个计数器，一个表示下一个可用票据，一个表示当前服务的票据，线程获取票据后等待其票据号被服务。

- **乐观锁（Optimistic Lock）**
  - **功能**：假设并发冲突不会频繁发生，在访问资源时不加锁，而是在提交修改时检查冲突，如果发生冲突则重试。
  - **特点**：通过减少锁的使用提高并发性能，适用于低冲突的场景。
  - **使用场景**：适用于低冲突的场景，如数据库读操作、缓存等。
  - **如何实现**：CAS+版本号，在提交修改时检查版本号或时间戳是否变化，如果发生冲突则重试。

#### 2.2 condition_variable

条件变量是一种“事件通知机制”，它本身不提供、也不能够实现“互斥”的功能。因此，条件变量通常（也必须）配合互斥量来一起使用，其中互斥量实现对“共享数据”的互斥（即同步），而条件变量则去执行 “通知共享数据状态信息的变化”的任务。比如通知队列为空、非空，或任何其他需要由线程处理的共享数据的状态变化。可以说，条件变量是程序用来等待某个状态为真的机制。而这个状态必须得是线程安全的，因此需要搭配互斥量使用。

在c++中，条件变量的关键词是`std::condition_variable`。它可以用来在多线程环境中实现复杂的同步模式。以下是一些常见的用法:

1.  **等待通知**:一个线程可以使用`std::condition_variable::wait`或`wait_for`/`wait_until`方法来等待另一个线程的通知。当`wait`被调用时，当前线程将被阻塞，直到另一个线程调用`std::condition_variable::notify_one`或`notify_all`方法。
2.  **条件等待**:`std::condition_variable::wait`方法还可以接受一个谓词(返回`bool`的函数或函数对象).只有当这个谓词返回`true`时，`wait`才会返回。这可以用来实现条件等待:线程等待某个条件成立。
3.  **唤醒一个或多个线程**:可以使用`std::condition_variable::notify_one`方法唤醒一个等待的线程，或者使用`std::condition_variable::notify_all`方法唤醒所有等待的线程。

#### 2.3 promise/ future

future 是表示未来能够得到的值，具体什么时候能够得到，依赖于承诺对象的实现。
什么是承诺对象？
promise 和 packaged_task 就是承诺对象，但这些承诺对象 set_value 的时候，就可以执行 future.get()

关于 future，promise，packaged_task，async 的理解，以下表述对吗？
promise 和 packaged_task 都是还没有给出具体值的承诺对象，当给出具体数值的时候，就表示承诺实现，可以用于计算。
而 async 是表示会开一个异步线程进行计算，返回的是一个 future 的值，如果 future 的值计算好之后，就可以通过 future.get()得到。

所以说，在一个异步计算中，promise 和 packaged_task 是输入端的，async 是输出端的。

##### 2.3.1 shared_future

`std::future`对象的设计是唯一所有权的，也就是说，一旦你从一个`std::future`对象中获取了值，这个`std::future`对象就不能再被用来获取值。这是因为`std::future::get`方法会移动(而不是复制)值或异常，这样可以避免不必要的复制，但也意味着你只能从一个`std::future`对象中获取值一次。

因此，如果你需要在多个线程中共享同一个值，你不能直接使用`std::future`，而应该使用`std::shared_future`.`std::shared_future`对象可以被多次拷贝和读取，这意味着你可以在多个线程中共享同一个值。

在你的代码中，你创建了一个`std::shared_future<int> sf`对象，并将它传递给了三个异步操作。这三个异步操作都可以通过`sf.get()`获取到同一个值。如果你试图直接使用`std::future<int> f`来做同样的事情，你会得到一个编译错误，因为`std::future`对象不能被拷贝。

- shared_future 可以直接对一个 promise 变量使用 get_future 方法吗

不可以。`std::promise`的`get_future`方法只能返回一个`std::future`对象，而不是`std::shared_future`对象。如果你想要一个`std::shared_future`对象，你需要首先从`std::promise`获取一个`std::future`对象，然后调用`std::future`的`share`方法来获取一个`std::shared_future`对象。例如:

```cpp
std::promise<int> p;
std::future<int> f = p.get_future();
std::shared_future<int> sf = f.share();
```

在这段代码中，`sf`是一个`std::shared_future`对象，它与`f`共享同一个状态，也就是说，它们都可以获取到同一个值。

#### 2.4 atomic

std::call_once 和 std::once_flag：
这些用于确保某个函数或操作只被调用一次，即使在多线程环境中也不会被重复执行。

- 解决多线程下共享变量的问题(i++，指令重排问题)：对于共享变量的访问进行加锁，加锁可以保证对临界区的互斥访问，
- C++11 提供了一些原子变量与原子操作解决用户加锁操作麻烦或者容易出错的问题
- C++11 标准在标准库 atomic 头文件提供了模版 std::atomic<>来定义原子量，而对于大部分内建类型，C++11 提供了一些特化，如，std::atomic_int (std::atomic<int>)等
- 自定义类型变成原子变量的条件是该类型必须为**Trivially Copyable 类型**(简单的判断标准就是这个类型可以用 std::memcpy 按位复制)
- atomic 有一个成员函数 is_lock_free，这个成员函数可以告诉我们到底这个类型的原子量是使用了原子 CPU 指令实现了无锁化，还是依然使用的加锁的方式来实现原子操作

##### 2.4.1 barrier

屏障主要用于多个线程之间的并行工作的协调。**屏障允许每个线程等待，直到所有的合作线程都达到某个点，然后从该点继续执行**

### 3. 标准库未直接提供的多线程工具

#### 3.1 信号量

`semaphore.h` 是一个头文件，提供信号量相关的功能，用于控制对共享资源的访问。C++20 标准库引入了信号量类 `std::counting_semaphore` 和 `std::binary_semaphore`，提供了类似 `semaphore.h` 的功能。通过使用 C++ 标准库中的信号量类，可以实现对共享资源的同步控制，解决多线程编程中的同步问题。

- 信号量可以决定线程当前是继续运行还是等待

- 信号量代表某一类资源，其值表示系统中该资源的数量。因此它是一个非负数的值

- 信号量是一个受保护的变量，只能通过三种操作来访问：
  - 初始化
  - P操作（申请资源）
    - 当进行P操作时，它会去**判断当前信号量的值是否大于0**，**若是，则申请P操作的任务继续运行，同时信号量的值减一**。**若否，则阻塞**
  - V操作（释放资源）
    - V操作则是**先让信号量的值加一**，**再判断当前是否有正在等待资源的任务以让它继续运行**

#### 3.2 临界区

### 4. 死锁的监测与避免

#### 4.1 死锁的必要条件

- 互斥：一些会被竞争的资源，一个时间只能被一个线程占用。
  > 解决方式：不上锁，用无锁方式；乐观锁模式；
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
  > 解决方式：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
  > 提供某种机制，或者允许系统强制回收资源。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。
  > 给资源统一编号，进程只能按编号顺序来请求资源。

(1) 互斥:一个资源每次只能被一个进程使用。<br>
(2) 占有并请求:一个进程因请求资源而阻塞时，对已获得的资源保持不放。<br>
(3) 不可剥夺:进程已获得的资源，在末使用完之前，不能强行剥夺。<br>
(4) 循环等待:若干进程之间形成一种头尾相接的循环等待资源关系。<br>

产生死锁的原因主要是:<br>
(1) 因为系统资源不足。<br>
(2) 进程运行推进的顺序不合适。<br>
(3) 资源分配不当等。<br>

#### 4.2 死锁的解决方法

- 死锁检测与死锁恢复
  通过系统监测死锁的发生，并在检测到死锁时采取措施恢复系统。
  具体方法包括终止一个或多个进程，或回收某些资源。

1. 重新启动:是最简单/最常用的死锁消除方法，但代价很大，因为在此之前所有进程已经完成的计算工作都将付之东流，不仅包括死锁的全部进程，也包括未参与死锁的全部进程。
2. 终止进程(process termination):终止参与死锁的进程并回收它们所占资源。
   (1) 一次性全部终止;(2) 逐步终止(优先级，代价函数)
3. 剥夺资源(resource preemption):剥夺死锁进程所占有的全部或者部分资源。
   (1) 逐步剥夺:一次剥夺死锁进程所占有的一个或一组资源，如果死锁尚未解除再继续剥夺，直至死锁解除为止。
   (2) 一次剥夺:一次性地剥夺死锁进程所占有的全部资源。
4. 进程回退(rollback):让参与死锁的进程回退到以前没有发生死锁的某个点处，并由此点开始继续执行，希望进程交叉执行时不再发生死锁。但是系统开销很大:
   (1) 要实现"回退"，必须"记住"以前某一点处的现场，而现场随着进程推进而动态变化，需要花费大量时间和空间。
   (2) 一个回退的进程应当"挽回"它在回退点之间所造成的影响，如修改某一文件，给其它进程发送消息等，这些在实现时是难以做到的

### 99. quiz

#### 1. `std::lock_guard`和`std::unique_lock`有什么不同？

`std::lock_guard` 和 `std::unique_lock` 都是 RAII（Resource Acquisition Is Initialization）风格的互斥锁包装器，它们在构造时自动锁定互斥锁，在析构时自动解锁互斥锁。这种设计可以确保在函数退出（无论是正常退出还是异常退出）时自动释放锁，从而避免因忘记解锁而导致的死锁。`std::lock_guard`和`std::unique_lock`的主要区别在于:

1.  **延迟锁定**：
    - `std::unique_lock` 可以在创建时不立即锁定互斥锁，然后在需要的时候再锁定。
    - `std::lock_guard` 则在创建时必须立即锁定互斥锁。
2.  **所有权传递**：
    - `std::unique_lock` 是可移动的，这意味着你可以将锁的所有权从一个 `std::unique_lock` 对象转移到另一个。
    - `std::lock_guard` 则不可移动。
3.  **手动锁定和解锁**：
    - `std::unique_lock` 提供了 `lock` 和 `unlock` 方法，允许你在任何时候手动锁定和解锁互斥锁。
    - `std::lock_guard` 则不提供这些方法。

简单来说，使用选择上：

- **`std::unique_lock`**：

  - 适用于需要更多控制的场景，例如延迟锁定、所有权传递或手动锁定和解锁。
  - 提供更大的灵活性，但相对开销也更大。

- **`std::lock_guard`**：
  - 适用于简单的锁定和解锁场景。
  - 更简单，且开销更小。

#### 2. `std::unique_lock`提供的锁策略参数是什么？

`std::adopt_lock`/`std::defer_lock` 和 `std::try_to_lock` 都是 `std::unique_lock` 的构造函数可以接受的锁策略参数，它们的含义和使用场景如下:

1.  **std::adopt_lock**:这个策略表示互斥锁在构造锁对象时已经被锁定。当你已经手动锁定了一个互斥锁，然后想要将它的管理权交给 `std::unique_lock` 时，可以使用 `std::adopt_lock`.这样，`std::unique_lock` 在构造时就不会再次尝试锁定互斥锁，而是直接接管已经被锁定的互斥锁。
2.  **std::defer_lock**:这个策略表示在构造 `std::unique_lock` 时不锁定互斥锁。你可以稍后手动调用 `std::unique_lock::lock` 方法来锁定互斥锁。这个策略在你需要延迟锁定互斥锁的情况下很有用。
3.  **std::try_to_lock**:这个策略表示在构造 `std::unique_lock` 时尝试锁定互斥锁，如果互斥锁已经被锁定，则立即返回，不会阻塞。你可以检查 `std::unique_lock::owns_lock` 方法的返回值，来判断是否成功锁定了互斥锁。

#### 3. 不使用 `join` 也不使用 `detach`，会发生什么

- **问题**：

  - 在主线程退出时，可能会导致一些未定义行为，因为线程对象将被销毁，但线程本身可能仍在运行。

- **可能发生的情况**：
  1. **程序可能终止，但线程可能仍在运行**：
  - 如果主线程退出，而被创建的线程仍在运行，可能导致程序终止，但线程继续执行。这可能导致线程无法正确完成其任务，因为主线程已经退出。
  2. **程序可能会崩溃**：
  - 这是由于线程对象的销毁可能涉及到一些资源的释放，而线程本身仍在访问这些资源，导致未定义行为。
  3. **资源泄漏**：
  - 如果线程分配了一些资源（例如内存），但在线程执行完毕前这些资源没有被释放，可能会导致资源泄漏。

#### 4. 为什么多线程传引用要用`std::ref`

问题出在 std::thread 不能直接传递引用类型参数。std::thread 在创建线程时会复制传入的参数。
因为主线程和子线程是两个声明周期，如果直接传递引用，当主线程中的对象销毁后，线程函数中的引用就会成为悬空引用，访问悬空引用会导致未定义行为。

如果能直接传递引用类型，因为线程的生命周期和原有函数不一定一直，可能会导致悬空引用。
而使用了std::ref本质上是没有解决悬空引用问题的，因此这个时候要开发者要有一个心智的认识，即这里的声明周期，以及会不会出现悬空引用。

```c++
#include <iostream>
#include <thread>

// 线程函数
void modifyValue(int& num) {
    num = 100;
    std::cout << "Value inside thread: " << num << std::endl;
}

int main() {
    int value = 10;
    // 创建线程，尝试传递引用
    // std::thread t(modifyValue， value); // error
    std::thread t(modifyValue， std::ref(value));
    t.join();
    std::cout << "Value outside thread: " << value << std::endl;
    return 0;
}
```

#### 3. 原子操作实现原理

原子操作通过硬件支持的原子指令和缓存行锁机制，确保在多核 CPU 环境中，对共享数据的操作是原子的。通过在操作期间将缓存行标记为 locked，可以防止多个 CPU 核心同时修改同一份数据，从而实现原子操作。这种实现方式要求操作的变量位于一个缓存行中。

- **Cache Line Lock 的实现步骤**

  1. **CPU1 发出 "Read Invalidate" 消息**：

  - CPU1 发出 "Read Invalidate" 消息，通知其他 CPU 将原子变量所在的缓存无效，并从 Cache 返回数据。
  - CPU1 将 Cache Line 置为 Exclusive 状态，并将该 Cache Line 标记为 locked。

  2. **CPU1 读取和修改原子变量**：

  - CPU1 读取原子变量，进行修改，并将修改后的数据写入 Cache Line。

  3. **将 Cache Line 置为 unlocked**：

  - CPU1 完成操作后，将 Cache Line 置为 unlocked。

- **处理并发操作**
  在步骤 (1) 和 (3) 之间，如果其他 CPU（例如 CPU0）尝试执行一个原子递增操作，以下是处理流程：

  1. **CPU0 发送 "Read Invalidate" 消息**：

  - CPU0 发送 "Read Invalidate" 消息，通知 CPU1 将原子变量所在的缓存无效。

  2. **CPU1 检查 Cache Line 状态**：

  - CPU1 收到消息后，检查对应的 Cache Line 的状态是 locked，暂时不回复消息。
  - CPU0 会一直等待 CPU1 回复 Invalidate Acknowledge 消息。

  3. **等待 Cache Line 变为 unlocked**：

  - CPU0 等待 Cache Line 变为 unlocked。
  - 当 CPU1 将 Cache Line 置为 unlocked 后，CPU0 收到 Invalidate Acknowledge 消息，继续执行原子操作。

- **总结**
  这种方式称为锁 Cache Line，通过在操作期间将 Cache Line 标记为 locked，确保在操作期间其他 CPU 核心无法修改该数据，从而实现原子操作。这种实现方式要求操作的变量位于一个 Cache Line 中。

#### 4. 多核 cpu 的缓存以及如何保持缓存一致性

在多核 CPU 环境中，每个 CPU 核心都有自己的高速缓存（Cache），用于加速数据访问。然而，当多个 CPU 核心同时操作同一份数据时，可能会导致数据不一致的问题。为了确保数据的一致性，多核 CPU 使用了一些机制来保持缓存一致性。

- **缓存一致性问题**

1. **缓存一致性问题**：
   - 当多个 CPU 核心同时读取和写入同一内存地址时，可能会导致缓存中的数据不一致。
   - 例如，CPU 核心 A 和 CPU 核心 B 都有一个变量 `x` 的缓存副本。如果 CPU 核心 A 修改了 `x` 的值，而 CPU 核心 B 仍然使用旧的缓存值，就会导致数据不一致。

- **缓存一致性协议**

为了保持缓存一致性，多核 CPU 使用了缓存一致性协议。以下是一些常见的缓存一致性协议：

1. **MESI 协议**：

   - MESI 协议是最常见的缓存一致性协议之一。MESI 是四个状态的缩写：Modified（修改）、Exclusive（独占）、Shared（共享）和 Invalid（无效）。
   - 每个缓存行都有一个状态，表示该缓存行的当前状态。

2. **MESI 协议的工作原理**：

   - **Modified（修改）**：缓存行的数据已被修改，与主内存中的数据不一致。只有一个 CPU 核心可以持有该状态的缓存行。
   - **Exclusive（独占）**：缓存行的数据与主内存中的数据一致，且只有一个 CPU 核心持有该缓存行。
   - **Shared（共享）**：缓存行的数据与主内存中的数据一致，且多个 CPU 核心可以持有该缓存行。
   - **Invalid（无效）**：缓存行的数据无效，不能使用。

3. **缓存一致性操作**：
   - **读取操作**：当一个 CPU 核心读取一个缓存行时，如果该缓存行的状态是 Invalid，则需要从主内存或其他 CPU 核心的缓存中获取最新的数据。
   - **写入操作**：当一个 CPU 核心写入一个缓存行时，需要通知其他 CPU 核心将该缓存行的状态设置为 Invalid。

#### 5. 什么是虚假唤醒？为什么会有虚假唤醒？可以避免虚假唤醒吗？

```c++
std::mutex mtx;
std::condition_variable cond;
std::deque<int> queue;

int dequeue() {
    std::unique_lock<std::mutex> lock(mtx);
    cond.wait(lock， [] { return !queue.empty(); });  // 使用 lambda 表达式检查条件
    int top = queue.front();
    queue.pop_front();
    return top;
}

int dequeue2() {
    std::unique_lock<std::mutex> lock(mtx);
    while (queue.empty()) {  // 不能用 if，必须用 while，避免虚假唤醒
        cond.wait(lock);
    }
    int top = queue.front();
    queue.pop_front();
    return top;
}

int dequeue3() {
    std::unique_lock<std::mutex> lock(mtx);
    if (queue.empty()) {  // 使用 if 判断，可能会出现虚假唤醒
        cond.wait(lock);
    }
    int top = queue.front();
    queue.pop_front();
    return top;
}
```

在多线程编程中，使用条件变量（Condition Variable）进行线程同步时，可能会遇到虚假唤醒的问题。以下是对虚假唤醒及其处理方法的详细解释：

- **什么是虚假唤醒？**
  虚假唤醒（Spurious Wakeup）是指线程在等待条件变量时，即使没有任何线程调用 `notify_one` 或 `notify_all`，也会被唤醒的情况，即`wait`的时候被唤醒了。这种现象在某些操作系统和硬件平台上可能会发生。

- **为什么会有虚假唤醒？**
  虚假唤醒的原因可能包括：

  1. **操作系统的调度策略**：

  - 操作系统可能会出于各种原因唤醒等待的线程，例如资源重新分配或优先级调整。

  2. **硬件中断**：

  - 硬件中断可能会导致等待的线程被唤醒。

  3. **其他系统级别的事件**：

  - 系统级别的事件（如信号处理）也可能导致线程被唤醒。

- **如何处理虚假唤醒？**
  为了正确处理虚假唤醒，通常在一个 `while` 循环中调用 `.wait()` 方法，而不是使用 `if` 判断。这样可以多次检验条件，确保条件满足后才继续执行。

- **总结**
  - **虚假唤醒**：虚假唤醒是指线程在等待条件变量时，即使没有任何线程调用 `notify_one` 或 `notify_all`，也会被唤醒的情况。
  - **原因**：虚假唤醒可能由操作系统的调度策略、硬件中断或其他系统级别的事件引起。
  - **处理方法**：为了正确处理虚假唤醒，通常在一个 `while` 循环中调用 `.wait()` 方法，确保每次被唤醒时都重新检查条件是否满足。

#### 6. 如果函数返回一个 future，对这个 future 不调用 get()，会发生什么

- **1. `std::async` 的返回值**

  - **临时 `std::future` 对象**：
    - 如果你调用 `std::async` 但不将返回值存储在一个 `std::future` 对象中，一个临时的 `std::future` 对象会被创建。
    - 这个临时对象会在表达式结束时被销毁，销毁时会阻塞等待异步任务完成。
    - 因此，如果你不想阻塞当前线程，不能简单地忽略 `std::async` 的返回值。你需要将返回的 `std::future` 对象存储在某个地方，以便在适当的时候等待任务完成。

- **2. `std::future` 的析构行为**

  - **阻塞等待异步任务完成**：
    - 如果你创建了一个 `std::future` 对象，但没有调用 `get()` 方法，那么在 `std::future` 对象被销毁时，如果关联的异步操作（例如 `std::async`）还没有完成，程序会阻塞，直到异步操作完成。
    - 这是因为 `std::future` 的析构函数会检查关联的异步操作是否已经完成。如果没有完成，析构函数会阻塞，直到异步操作完成。这是为了确保异步操作能够安全地完成，而不会在还没有完成的情况下被强制停止。

- **3. 避免阻塞的方法**

  - **使用 `std::future::detach()`**：
    - 如果你不想在 `std::future` 对象被销毁时阻塞，可以调用 `std::future::detach()` 方法。这将使 `std::future` 对象与其关联的异步操作分离，这样，即使 `std::future` 对象被销毁，异步操作也会继续运行。
    - 需要注意的是，如果你没有调用 `get()` 方法，那么你将无法获取异步操作的结果。此外，`get()` 方法只能被调用一次，因为调用 `get()` 方法后，`std::future` 对象会变为无效状态。

- **4. 函数返回值的处理**

  - **函数返回值的析构**：
    - 函数的返回值即使没有用变量接收，实际上也是存在的，并且在外部函数结束时会被析构。
    - 而 `std::future` 的析构又要确保 `get()` 方法完成，所以如果不接收返回值，就会产生阻塞。

- **总结**
  在使用 `std::async` 和 `std::future` 时，需要注意以下几点：

  - 将 `std::async` 的返回值存储在 `std::future` 对象中，以避免临时对象销毁时阻塞当前线程。
  - 在 `std::future` 对象被销毁前，调用 `get()` 方法等待异步任务完成，或使用 `detach` 方法分离异步操作。
  - 理解 `std::future` 的析构行为，确保异步操作能够安全地完成。

#### 7. 对于单次事件通信使用atomic， mutex， promise的比较

这段文本讨论了在多线程编程中，如何有效地进行单次事件通信。具体来说，它比较了使用标志位、线程锁和`std::promise`三种不同的方法来实现线程间的同步和通信。

1. **使用标志位(flag)**:

   - 代码示例中没有直接展示，但提到了一种常见的做法，即在一个线程中使用`while(!flag){}`循环等待另一个线程改变`flag`的值。这种方法简单，但它会导致忙等待（busy-waiting），浪费 CPU 资源，因为等待的线程会持续检查`flag`而不做任何有用的工作。

2. **使用线程锁**:

   - 文本提到可以使用线程锁来代替标志位，以避免忙等待。示例代码中，`std::lock_guard<std::mutex>`用于自动管理互斥锁，但示例似乎有误，因为它没有展示如何正确使用互斥锁来等待某个条件。正确的做法通常涉及到`std::condition_variable`，它可以与互斥锁一起使用，让线程在条件不满足时休眠，直到条件被另一个线程改变并通知。

3. **使用`std::promise`**:
   - 最后，文本推荐使用`std::promise`来进行单次事件通信。`std::promise`是一种同步机制，可以在一个线程中存储一个值或异常，然后在另一个线程中通过与之对应的`std::future`对象来检索这个值或异常。示例中，`detect`函数创建了一个线程`t`，这个线程会等待`std::promise`对象`p`的状态被设置。当`detect`函数调用`p.set_value()`时，`p`的状态被设置，`t`中的等待操作完成，`react`函数随后被执行。这种方法避免了忙等待，且只适用于一次性通信，但需要注意的是，它可能涉及到堆内存的使用。

总的来说，这段文本强调了在设计多线程程序时，应该避免使用忙等待策略，而应该考虑使用更高级的同步机制，如`std::promise`，来高效地进行线程间的单次事件通信。

#### 12. CAS，非阻塞同步（乐观锁）

随着硬件指令集的发展，出现了基于冲突检测的乐观并发策略。通俗地说，**乐观锁**的思想是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采用其他的补偿措施（最常见的补偿措施是不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为**非阻塞同步**。

- **CAS 指令**

  - **定义**：
    - CAS 指令需要有 3 个操作数，分别是内存地址（在 Java 中理解为变量的内存地址，用 V 表示）、旧的预期值（用 A 表示）和新值（用 B 表示）。
    - CAS 指令执行时，当且仅当 V 处的值符合旧预期值 A 时，处理器用 B 更新 V 处的值，否则它就不执行更新。
    - 无论是否更新了 V 处的值，都会返回 V 的旧值。上述的 CAS 指令是一个原子操作。

- **CAS 的 ABA 问题**

  - **定义**：

    - 因为 CAS 需要在操作值的时候检查值有没有发生变化，如果没有发生变化则更新。但是一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但实际上却变化了。
    - CAS 只关注了比较前后的值是否改变，而无法清楚在此过程中变量的变更明细，这就是所谓的 ABA 问题。

  - **解决思路**：
    - 使用版本号（如 MySQL 的 MVCC）。在变量前面追加版本号，每次变量更新的时候把版本号加一，那么 A-B-A 就变成了 1A-2B-3A，从而解决 ABA 问题。

#### 13. 什么是析构竞态？

- **可能出现的竞态条件**

  1. **对象即将析构时**：

  - 如何确定是否有其他线程正在执行该对象的成员函数？
  - 如果在析构对象时，另一个线程正在调用该对象的成员函数，可能会导致未定义行为。

  2. **执行成员函数期间**：

  - 如何保证在执行成员函数期间，对象不会在另一个线程被析构？
  - 如果对象在执行成员函数期间被析构，可能会导致程序崩溃或数据损坏。

  3. **调用成员函数之前**：

  - 如何得知对象在调用成员函数之前还活着？
  - 如果对象的析构函数正在执行，调用成员函数可能会导致未定义行为。

- **解决方法**
  为了避免析构竞态，可以使用以下方法：

  1. **智能指针**：

     - 使用 `std::shared_ptr` 和 `std::weak_ptr` 来管理对象的生命周期。
     - `std::shared_ptr` 会自动管理对象的引用计数，当引用计数为零时，自动销毁对象。
     - `std::weak_ptr` 可以安全地访问 `std::shared_ptr` 管理的对象，而不会影响对象的生命周期。

  2. **互斥锁**：

     - 使用互斥锁（如 `std::mutex`）来保护对象的访问和析构操作。
     - 在访问对象的成员函数时，先获取锁，确保对象在访问期间不会被析构。

#### 14. 如何从构造函数，实现线程安全？

要确保对象构造期间的线程安全，关键在于避免在构造函数中泄露 `this` 指针。具体来说：

1. **不要在构造函数中注册任何回调**：

   - 在构造函数中注册回调可能会导致 `this` 指针泄露，从而使得其他线程在对象尚未完全构造完成时访问它。

2. **不要在构造函数中把 `this` 传给跨线程的对象**：

   - 在构造函数中将 `this` 传递给其他线程的对象可能会导致这些线程在对象尚未完全构造完成时访问它。

3. **即便在构造函数的最后一行也不行**：

   - 即使在构造函数的最后一行将 `this` 传递给其他线程的对象也可能导致竞态条件，因为对象的构造尚未完全完成。

#### 15. 为什么线程安全的，析构函数这么麻烦？

线程安全的析构函数复杂的原因主要在于析构过程中需要销毁互斥锁，同时确保没有其他线程在使用该对象。具体来说：

1. **确保所有线程都已经停止使用对象**：

   - 在销毁对象之前，必须确保没有任何线程还在使用或可能会使用该对象。这通常需要使用同步机制（如条件变量或 `std::future`）来等待所有线程完成。

2. **使用智能指针管理资源**：

   - 在 C++ 中，可以使用智能指针（如 `std::unique_ptr` 或 `std::shared_ptr`）来管理对象。当没有任何指针指向对象时，对象会被自动销毁。这可以避免手动管理内存和资源的复杂性。

你将从本书中获得从进程与线程的关系，再到常用的线程同步原语的区别与使用场景，再到线程池以及基于生产者消费者模型的消息队列，以及对协程思想介绍的相关知识。

掌握了常见的多线程同步原语之后，接下来可以找一些带多线程的项目去学习一下，不管是否带 UI的都行。
我推荐的一种方式是，使用 gdb 或者 Visual Studio 调试器将你需要学习的多线程程序中断下来，在多线程面板，看看这个进程一共有多少个正在运行的线程，分析每个线程的作用，然后研究下这些线程在何时何地创建的，为什么需要创建新的线程。

#### 16. thread里面的变量是独立于主线程的

- 如果传递的是指针，要注意主线程析构之后，子线程无法访问
- 如果子线程要求传递的是引用，因为thread的构造函数不知道要传递引用，所以要用ref
- 如果子线程要求运行的是某个实例的成员函数也是可以的。

简单来说，参数都是先被拷贝到thread，再到函数的。
因为创建thread的时候，也不能提前预知函数要什么类型的。
那这个过程中，传递参数如果是可以隐式转换的，那thread可能就传不对了。
而如果传递的是引用的话，thread也不知道，只当成是一个指针，再到函数就傻眼了。
